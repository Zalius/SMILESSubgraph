{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_uT3IYjIBot"
   },
   "source": [
    "# Installing Packages and Frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dswd7QyGVBd",
    "outputId": "048402dd-f4cf-42af-85fe-2effa54cdab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnJ6R1pfH-nH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.data import NeighborSampler, Data, Dataset\n",
    "from torch_geometric.utils import negative_sampling, convert, to_dense_adj\n",
    "from torch_geometric.utils import subgraph, to_networkx, from_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import to_torch_csc_tensor\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "from ogb.io import DatasetSaver\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so8HJQ4VIFZl"
   },
   "source": [
    "# Building Subgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7elDpkfIOWR",
    "outputId": "99752e88-8003-4829-e608-15beb5821917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/linkproppred/ddi.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.04 GB: 100%|██████████| 46/46 [00:00<00:00, 56.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/ddi.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 660.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "The ogbl-ddi dataset has 1 graph(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the ogbl-ddi dataset\n",
    "dataset_name = 'ogbl-ddi'\n",
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "# dataset = PygLinkPropPredDataset(name='ogbl-ddi',\n",
    "#                                      transform=T.ToSparseTensor())\n",
    "print(f'The {dataset_name} dataset has {len(dataset)} graph(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS3Ku11XIOYZ"
   },
   "outputs": [],
   "source": [
    "ddi_graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhX8Dd0KIXFv"
   },
   "outputs": [],
   "source": [
    "#Finding the right nodes to choose:\n",
    "df = pd.read_csv(\"data/dataWithSmiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nj379su9Iedb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/node_features.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m----> 2\u001b[0m     node_features \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train_pos.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m      4\u001b[0m     train_pos \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('data/node_features.pickle', 'rb') as handle:\n",
    "    node_features = pickle.load(handle)\n",
    "with open('data/train_pos.pickle', 'rb') as handle:\n",
    "    train_pos = pickle.load(handle)\n",
    "with open('data/valid_pos.pickle', 'rb') as handle:\n",
    "    valid_pos = pickle.load(handle)\n",
    "with open('data/valid_neg.pickle', 'rb') as handle:\n",
    "    valid_neg = pickle.load(handle)\n",
    "with open('data/test_pos.pickle', 'rb') as handle:\n",
    "    test_pos = pickle.load(handle)\n",
    "with open('data/test_neg.pickle', 'rb') as handle:\n",
    "    test_neg = pickle.load(handle)\n",
    "with open('data/nodes.pickle', 'rb') as handle:\n",
    "    nodes = pickle.load(handle)\n",
    "with open('data/nodes_removed.pickle', 'rb') as handle:\n",
    "    nodes_removed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsgfzisZIz8M",
    "outputId": "6e9fac36-e425-4e29-92e9-f856905e042e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training positive edges: 887234\n",
      "Number of validation positive edges: 111117\n",
      "Number of validation negative edges: 74182\n",
      "Number of test positive edges: 114869\n",
      "Number of test negative edges: 70962\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training positive edges: {train_pos.shape[0]}')\n",
    "print(f'Number of validation positive edges: {valid_pos.shape[0]}')\n",
    "print(f'Number of validation negative edges: {valid_neg.shape[0]}')\n",
    "print(f'Number of test positive edges: {test_pos.shape[0]}')\n",
    "print(f'Number of test negative edges: {test_neg.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhPdVLcLbYUl"
   },
   "outputs": [],
   "source": [
    "nodes = torch.tensor(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VM-1dNRbYXF"
   },
   "outputs": [],
   "source": [
    "data = dataset[0].subgraph(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl6pAPBUj0Bx"
   },
   "source": [
    "# Training and Evaluation of Subgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WXEOPCC8R99"
   },
   "outputs": [],
   "source": [
    "def get_spd_matrix(G, S, max_spd=5):\n",
    "    spd_matrix = np.zeros((G.number_of_nodes(), len(S)), dtype=np.float32)\n",
    "    for i, node_S in enumerate(S):\n",
    "        for node, length in nx.shortest_path_length(G, source=node_S).items():\n",
    "            spd_matrix[node, i] = min(length, max_spd)\n",
    "    return spd_matrix\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 2\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 0].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Valid: {result[:, 0].max():.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 1]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                valid = r[:, 0].max().item()\n",
    "                test = r[r[:, 0].argmax(), 1].item()\n",
    "                best_results.append((valid, test))\n",
    "            best_result = torch.tensor(best_results)\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Valid: {r.mean():.4f} ± {r.std():.4f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'   Final Test: {r.mean():.4f} ± {r.std():.4f}')\n",
    "\n",
    "\n",
    "class SAGEConv(MessagePassing):\n",
    "    r\"\"\"The GraphSAGE operator from the `\"Inductive Representation Learning on\n",
    "    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{W}_2 \\cdot\n",
    "        \\mathrm{mean}_{j \\in \\mathcal{N(i)}} \\mathbf{x}_j\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        normalize (bool, optional): If set to :obj:`True`, output features\n",
    "            will be :math:`\\ell_2`-normalized, *i.e.*,\n",
    "            :math:`\\frac{\\mathbf{x}^{\\prime}_i}\n",
    "            {\\| \\mathbf{x}^{\\prime}_i \\|_2}`.\n",
    "            (default: :obj:`False`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                 out_channels: int, normalize: bool = False,\n",
    "                 root_weight: bool = True,\n",
    "                 bias: bool = True, **kwargs):  # yapf: disable\n",
    "        kwargs.setdefault('aggr', 'mean')\n",
    "        super(SAGEConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = Linear(in_channels[0], out_channels, bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor = None, size: Size = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        # Node and edge feature dimensionalites need to match.\n",
    "        if isinstance(edge_index, Tensor):\n",
    "            assert edge_attr is not None\n",
    "            assert x[0].size(-1) == edge_attr.size(-1)\n",
    "        elif isinstance(edge_index, SparseTensor):\n",
    "            assert x[0].size(-1) == edge_index.size(-1)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=size)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        return F.relu(x_j + edge_attr)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n",
    "\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
    "        super(GraphSAGE,self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t, edge_attr, emb_ea):\n",
    "        edge_attr = torch.mm(edge_attr, emb_ea)\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t, edge_attr)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t, edge_attr)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7QNIUeA8SAT"
   },
   "outputs": [],
   "source": [
    "def train(model, predictor, edge_attr, x, emb_ea, adj_t, train_edge, optimizer, batch_size):\n",
    "    edge_index = adj_t\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = train_edge.to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size, shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t, edge_attr, emb_ea)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYusvZDR8SFY"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, predictor, edge_attr, x, emb_ea, adj_t, pos_valid, neg_valid, pos_test, neg_test, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(x, adj_t, edge_attr, emb_ea)\n",
    "\n",
    "    pos_valid_edge = pos_valid.to(x.device)\n",
    "    neg_valid_edge = neg_valid.to(x.device)\n",
    "    pos_test_edge = pos_test.to(x.device)\n",
    "    neg_test_edge = neg_test.to(x.device)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [20, 50, 100]:\n",
    "        evaluator.K = K\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (valid_hits, test_hits)\n",
    "\n",
    "    return results, pos_valid_pred, neg_valid_pred, pos_test_pred, neg_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXcQLqDk8SHr"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_layers = 2\n",
    "num_samples = 5\n",
    "node_emb = 256\n",
    "hidden_channels = 256\n",
    "dropout = 0.3\n",
    "batch_size = 64 * 1024\n",
    "lr = 0.003\n",
    "epochs = 400\n",
    "log_steps = 1\n",
    "eval_steps = 1\n",
    "runs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6o_oO_p8SJm"
   },
   "outputs": [],
   "source": [
    "edge_index = data.edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ok9CR5Z8SLs",
    "outputId": "9799766e-f251-49f7-eaa4-3b1b455296e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3408, 2126, 3408,  ...,  254,  742, 2975],\n",
       "        [2126, 3408, 3303,  ...,  618, 2975,  742]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGBlU-LK8SO-"
   },
   "outputs": [],
   "source": [
    "model = GraphSAGE(node_emb, hidden_channels, hidden_channels,\n",
    "                      num_layers, dropout).to(device)\n",
    "emb = torch.nn.Embedding(data.num_nodes, node_emb).to(device)\n",
    "emb_ea = torch.nn.Embedding(num_samples, node_emb).to(device)\n",
    "predictor = LinkPredictor(hidden_channels, hidden_channels, 1,\n",
    "                              num_layers+1, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxbvZz_G90a7",
    "outputId": "9a091738-a4e8-4ec1-c828-ad756fc8130f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1301761\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters:',\n",
    "          sum(p.numel() for p in list(model.parameters()) +\n",
    "          list(predictor.parameters()) + list(emb.parameters()) + list(emb_ea.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Wh9YKYW90c3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "nx_graph = to_networkx(data, to_undirected=True)\n",
    "node_mask = []\n",
    "for _ in range(num_samples):\n",
    "    node_mask.append(np.random.choice(500, size=200, replace=False))\n",
    "node_mask = np.array(node_mask)\n",
    "node_subset = np.random.choice(nx_graph.number_of_nodes(), size=500, replace=False)\n",
    "spd = get_spd_matrix(G=nx_graph, S=node_subset, max_spd=5)\n",
    "spd = torch.Tensor(spd).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7spK7lQ90fM"
   },
   "outputs": [],
   "source": [
    "edge_attr = spd[edge_index, :].mean(0)[:, node_mask].mean(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRrLQDyR90hB"
   },
   "outputs": [],
   "source": [
    "a_max = torch.max(edge_attr, dim=0, keepdim=True)[0]\n",
    "a_min = torch.min(edge_attr, dim=0, keepdim=True)[0]\n",
    "edge_attr = (edge_attr - a_min) / (a_max - a_min + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Wn315cB-yCx"
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcPhjmxY-l_O",
    "outputId": "a745adcd-7cab-4ffe-ed88-42e73c3cdd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(device=0, num_layers=2, num_samples=5, node_emb=256, hidden_channels=256, dropout=0.3, batch_size=65536, lr=0.003, epochs=400, log_steps=1, eval_steps=1, runs=2, file='/root/.local/share/jupyter/runtime/kernel-f5e7f22a-f782-4547-878b-9ddb736657ef.json')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Link_Pred_DDI')\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--num_layers', type=int, default=2)\n",
    "parser.add_argument('--num_samples', type=int, default=5)\n",
    "parser.add_argument('--node_emb', type=int, default=256)\n",
    "parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "parser.add_argument('--dropout', type=float, default=0.3)\n",
    "parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "parser.add_argument('--lr', type=float, default=0.003)\n",
    "parser.add_argument('--epochs', type=int, default=400)\n",
    "parser.add_argument('--log_steps', type=int, default=1)\n",
    "parser.add_argument('--eval_steps', type=int, default=1)\n",
    "parser.add_argument('--runs', type=int, default=2)\n",
    "parser.add_argument(\"-f\", \"--file\", required=False)\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ov2x-nd-Qlw"
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='ogbl-ddi')\n",
    "loggers = {\n",
    "    'Hits@20': Logger(runs, args),\n",
    "    'Hits@50': Logger(args.runs, args),\n",
    "    'Hits@100': Logger(args.runs, args),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNhdVZL4-QoX",
    "outputId": "a2072f45-108e-4284-e444-02bed0cc3edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 92, Loss: 0.2041, Valid: 61.70%, Test: 49.30%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 92, Loss: 0.2041, Valid: 67.34%, Test: 77.16%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 92, Loss: 0.2041, Valid: 69.79%, Test: 88.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 93, Loss: 0.2040, Valid: 63.89%, Test: 15.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 93, Loss: 0.2040, Valid: 68.10%, Test: 57.46%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 93, Loss: 0.2040, Valid: 69.89%, Test: 85.68%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 94, Loss: 0.2047, Valid: 63.13%, Test: 44.88%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 94, Loss: 0.2047, Valid: 67.85%, Test: 74.94%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 94, Loss: 0.2047, Valid: 70.26%, Test: 89.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 95, Loss: 0.2025, Valid: 65.04%, Test: 24.34%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 95, Loss: 0.2025, Valid: 67.88%, Test: 77.71%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 95, Loss: 0.2025, Valid: 70.10%, Test: 89.07%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 96, Loss: 0.2029, Valid: 63.04%, Test: 56.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 96, Loss: 0.2029, Valid: 67.17%, Test: 76.76%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 96, Loss: 0.2029, Valid: 69.98%, Test: 87.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 97, Loss: 0.2027, Valid: 63.73%, Test: 50.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 97, Loss: 0.2027, Valid: 68.10%, Test: 75.36%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 97, Loss: 0.2027, Valid: 70.24%, Test: 86.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 98, Loss: 0.2022, Valid: 65.04%, Test: 59.73%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 98, Loss: 0.2022, Valid: 68.46%, Test: 77.13%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 98, Loss: 0.2022, Valid: 70.59%, Test: 89.68%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 99, Loss: 0.1995, Valid: 65.31%, Test: 41.85%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 99, Loss: 0.1995, Valid: 68.41%, Test: 71.84%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 99, Loss: 0.1995, Valid: 70.28%, Test: 88.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Loss: 0.2023, Valid: 65.41%, Test: 59.14%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Loss: 0.2023, Valid: 68.94%, Test: 84.42%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Loss: 0.2023, Valid: 70.74%, Test: 91.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 101, Loss: 0.2008, Valid: 65.40%, Test: 53.49%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 101, Loss: 0.2008, Valid: 68.53%, Test: 82.66%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 101, Loss: 0.2008, Valid: 70.51%, Test: 90.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 102, Loss: 0.1985, Valid: 63.65%, Test: 32.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 102, Loss: 0.1985, Valid: 68.41%, Test: 71.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 102, Loss: 0.1985, Valid: 70.61%, Test: 89.06%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 103, Loss: 0.2002, Valid: 61.26%, Test: 45.38%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 103, Loss: 0.2002, Valid: 68.17%, Test: 72.75%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 103, Loss: 0.2002, Valid: 70.48%, Test: 89.68%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 104, Loss: 0.1981, Valid: 64.30%, Test: 33.36%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 104, Loss: 0.1981, Valid: 68.64%, Test: 71.29%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 104, Loss: 0.1981, Valid: 70.70%, Test: 90.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 105, Loss: 0.1981, Valid: 63.89%, Test: 27.81%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 105, Loss: 0.1981, Valid: 68.48%, Test: 60.00%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 105, Loss: 0.1981, Valid: 70.53%, Test: 86.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 106, Loss: 0.1974, Valid: 64.34%, Test: 53.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 106, Loss: 0.1974, Valid: 69.20%, Test: 73.80%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 106, Loss: 0.1974, Valid: 70.72%, Test: 90.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 107, Loss: 0.1963, Valid: 65.84%, Test: 41.92%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 107, Loss: 0.1963, Valid: 69.10%, Test: 76.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 107, Loss: 0.1963, Valid: 71.14%, Test: 91.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 108, Loss: 0.1967, Valid: 65.41%, Test: 39.26%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 108, Loss: 0.1967, Valid: 68.91%, Test: 78.31%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 108, Loss: 0.1967, Valid: 70.87%, Test: 91.27%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 109, Loss: 0.1953, Valid: 64.56%, Test: 50.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 109, Loss: 0.1953, Valid: 69.18%, Test: 83.44%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 109, Loss: 0.1953, Valid: 71.12%, Test: 91.28%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 110, Loss: 0.1964, Valid: 64.87%, Test: 41.30%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 110, Loss: 0.1964, Valid: 69.44%, Test: 76.21%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 110, Loss: 0.1964, Valid: 71.34%, Test: 90.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 111, Loss: 0.1977, Valid: 66.26%, Test: 38.37%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 111, Loss: 0.1977, Valid: 69.49%, Test: 72.66%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 111, Loss: 0.1977, Valid: 71.25%, Test: 91.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 112, Loss: 0.1958, Valid: 67.02%, Test: 65.48%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 112, Loss: 0.1958, Valid: 69.29%, Test: 85.02%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 112, Loss: 0.1958, Valid: 71.21%, Test: 91.28%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 113, Loss: 0.1957, Valid: 61.97%, Test: 39.66%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 113, Loss: 0.1957, Valid: 68.28%, Test: 72.76%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 113, Loss: 0.1957, Valid: 70.82%, Test: 87.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 114, Loss: 0.1961, Valid: 63.15%, Test: 55.66%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 114, Loss: 0.1961, Valid: 69.19%, Test: 85.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 114, Loss: 0.1961, Valid: 71.51%, Test: 91.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 115, Loss: 0.1945, Valid: 64.66%, Test: 49.00%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 115, Loss: 0.1945, Valid: 68.75%, Test: 79.09%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 115, Loss: 0.1945, Valid: 71.18%, Test: 91.05%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 116, Loss: 0.1933, Valid: 64.47%, Test: 45.50%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 116, Loss: 0.1933, Valid: 69.30%, Test: 84.78%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 116, Loss: 0.1933, Valid: 71.65%, Test: 92.22%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 117, Loss: 0.1922, Valid: 65.26%, Test: 42.93%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 117, Loss: 0.1922, Valid: 68.98%, Test: 77.73%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 117, Loss: 0.1922, Valid: 71.42%, Test: 90.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 118, Loss: 0.1937, Valid: 62.18%, Test: 36.75%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 118, Loss: 0.1937, Valid: 69.29%, Test: 80.57%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 118, Loss: 0.1937, Valid: 71.60%, Test: 91.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 119, Loss: 0.1919, Valid: 65.37%, Test: 56.94%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 119, Loss: 0.1919, Valid: 69.62%, Test: 86.83%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 119, Loss: 0.1919, Valid: 71.66%, Test: 92.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 120, Loss: 0.1927, Valid: 65.68%, Test: 43.03%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 120, Loss: 0.1927, Valid: 69.53%, Test: 81.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 120, Loss: 0.1927, Valid: 71.89%, Test: 92.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 121, Loss: 0.1908, Valid: 64.90%, Test: 33.03%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 121, Loss: 0.1908, Valid: 69.97%, Test: 80.38%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 121, Loss: 0.1908, Valid: 72.09%, Test: 92.93%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 122, Loss: 0.1917, Valid: 66.52%, Test: 40.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 122, Loss: 0.1917, Valid: 69.54%, Test: 78.07%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 122, Loss: 0.1917, Valid: 71.40%, Test: 91.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 123, Loss: 0.1915, Valid: 64.73%, Test: 47.74%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 123, Loss: 0.1915, Valid: 69.63%, Test: 83.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 123, Loss: 0.1915, Valid: 71.75%, Test: 92.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 124, Loss: 0.1923, Valid: 62.49%, Test: 29.92%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 124, Loss: 0.1923, Valid: 69.60%, Test: 79.99%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 124, Loss: 0.1923, Valid: 71.50%, Test: 92.89%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 125, Loss: 0.1916, Valid: 63.92%, Test: 33.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 125, Loss: 0.1916, Valid: 69.47%, Test: 78.41%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 125, Loss: 0.1916, Valid: 71.68%, Test: 93.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 126, Loss: 0.1902, Valid: 61.67%, Test: 38.64%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 126, Loss: 0.1902, Valid: 69.39%, Test: 78.33%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 126, Loss: 0.1902, Valid: 71.58%, Test: 92.27%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 127, Loss: 0.1901, Valid: 63.05%, Test: 41.87%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 127, Loss: 0.1901, Valid: 69.39%, Test: 81.82%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 127, Loss: 0.1901, Valid: 71.55%, Test: 93.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 128, Loss: 0.1899, Valid: 65.24%, Test: 28.44%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 128, Loss: 0.1899, Valid: 69.97%, Test: 82.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 128, Loss: 0.1899, Valid: 71.75%, Test: 93.01%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 129, Loss: 0.1900, Valid: 64.78%, Test: 51.72%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 129, Loss: 0.1900, Valid: 69.49%, Test: 77.89%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 129, Loss: 0.1900, Valid: 71.70%, Test: 92.27%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 130, Loss: 0.1890, Valid: 65.88%, Test: 59.94%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 130, Loss: 0.1890, Valid: 69.85%, Test: 85.27%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 130, Loss: 0.1890, Valid: 71.80%, Test: 92.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 131, Loss: 0.1885, Valid: 63.24%, Test: 36.01%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 131, Loss: 0.1885, Valid: 69.49%, Test: 75.69%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 131, Loss: 0.1885, Valid: 71.78%, Test: 92.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 132, Loss: 0.1891, Valid: 66.10%, Test: 35.55%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 132, Loss: 0.1891, Valid: 69.29%, Test: 71.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 132, Loss: 0.1891, Valid: 71.56%, Test: 91.92%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 133, Loss: 0.1883, Valid: 63.00%, Test: 29.28%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 133, Loss: 0.1883, Valid: 69.79%, Test: 76.44%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 133, Loss: 0.1883, Valid: 71.69%, Test: 91.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 134, Loss: 0.1883, Valid: 66.38%, Test: 49.04%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 134, Loss: 0.1883, Valid: 70.29%, Test: 85.04%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 134, Loss: 0.1883, Valid: 72.18%, Test: 94.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 135, Loss: 0.1898, Valid: 63.51%, Test: 47.10%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 135, Loss: 0.1898, Valid: 70.58%, Test: 80.39%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 135, Loss: 0.1898, Valid: 72.20%, Test: 93.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 136, Loss: 0.1882, Valid: 65.41%, Test: 65.33%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 136, Loss: 0.1882, Valid: 70.74%, Test: 88.26%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 136, Loss: 0.1882, Valid: 72.24%, Test: 94.33%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 137, Loss: 0.1886, Valid: 64.95%, Test: 59.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 137, Loss: 0.1886, Valid: 70.22%, Test: 88.13%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 137, Loss: 0.1886, Valid: 72.21%, Test: 94.60%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 138, Loss: 0.1861, Valid: 64.60%, Test: 67.27%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 138, Loss: 0.1861, Valid: 70.19%, Test: 87.16%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 138, Loss: 0.1861, Valid: 72.19%, Test: 94.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 139, Loss: 0.1857, Valid: 65.45%, Test: 33.79%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 139, Loss: 0.1857, Valid: 70.95%, Test: 71.58%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 139, Loss: 0.1857, Valid: 72.43%, Test: 94.13%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 140, Loss: 0.1866, Valid: 64.91%, Test: 42.78%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 140, Loss: 0.1866, Valid: 70.48%, Test: 83.85%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 140, Loss: 0.1866, Valid: 72.11%, Test: 93.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 141, Loss: 0.1853, Valid: 63.76%, Test: 62.68%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 141, Loss: 0.1853, Valid: 70.45%, Test: 88.82%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 141, Loss: 0.1853, Valid: 72.38%, Test: 94.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 142, Loss: 0.1860, Valid: 65.19%, Test: 65.87%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 142, Loss: 0.1860, Valid: 70.49%, Test: 89.67%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 142, Loss: 0.1860, Valid: 72.35%, Test: 94.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 143, Loss: 0.1858, Valid: 66.27%, Test: 75.33%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 143, Loss: 0.1858, Valid: 71.16%, Test: 89.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 143, Loss: 0.1858, Valid: 72.86%, Test: 94.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 144, Loss: 0.1845, Valid: 65.39%, Test: 58.66%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 144, Loss: 0.1845, Valid: 70.81%, Test: 90.44%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 144, Loss: 0.1845, Valid: 72.34%, Test: 94.91%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 145, Loss: 0.1855, Valid: 65.39%, Test: 48.49%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 145, Loss: 0.1855, Valid: 70.68%, Test: 86.86%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 145, Loss: 0.1855, Valid: 72.12%, Test: 94.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 146, Loss: 0.1857, Valid: 64.84%, Test: 41.82%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 146, Loss: 0.1857, Valid: 70.70%, Test: 85.20%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 146, Loss: 0.1857, Valid: 72.22%, Test: 93.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 147, Loss: 0.1863, Valid: 66.80%, Test: 51.07%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 147, Loss: 0.1863, Valid: 70.69%, Test: 81.51%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 147, Loss: 0.1863, Valid: 72.27%, Test: 93.39%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 148, Loss: 0.1848, Valid: 65.29%, Test: 40.67%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 148, Loss: 0.1848, Valid: 70.30%, Test: 84.76%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 148, Loss: 0.1848, Valid: 72.28%, Test: 93.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 149, Loss: 0.1852, Valid: 66.04%, Test: 43.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 149, Loss: 0.1852, Valid: 71.06%, Test: 83.13%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 149, Loss: 0.1852, Valid: 72.42%, Test: 94.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 150, Loss: 0.1839, Valid: 63.62%, Test: 61.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 150, Loss: 0.1839, Valid: 70.81%, Test: 89.43%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 150, Loss: 0.1839, Valid: 72.17%, Test: 95.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 151, Loss: 0.1839, Valid: 67.41%, Test: 78.67%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 151, Loss: 0.1839, Valid: 70.90%, Test: 90.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 151, Loss: 0.1839, Valid: 72.31%, Test: 95.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 152, Loss: 0.1845, Valid: 65.92%, Test: 65.88%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 152, Loss: 0.1845, Valid: 71.10%, Test: 88.79%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 152, Loss: 0.1845, Valid: 72.34%, Test: 95.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 153, Loss: 0.1835, Valid: 64.66%, Test: 40.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 153, Loss: 0.1835, Valid: 70.42%, Test: 85.68%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 153, Loss: 0.1835, Valid: 72.45%, Test: 94.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 154, Loss: 0.1829, Valid: 64.42%, Test: 64.64%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 154, Loss: 0.1829, Valid: 70.89%, Test: 91.89%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 154, Loss: 0.1829, Valid: 72.44%, Test: 95.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 155, Loss: 0.1829, Valid: 65.56%, Test: 45.63%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 155, Loss: 0.1829, Valid: 70.84%, Test: 89.43%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 155, Loss: 0.1829, Valid: 72.68%, Test: 95.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 156, Loss: 0.1832, Valid: 64.04%, Test: 62.94%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 156, Loss: 0.1832, Valid: 70.95%, Test: 85.71%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 156, Loss: 0.1832, Valid: 72.29%, Test: 95.05%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 157, Loss: 0.1820, Valid: 63.17%, Test: 44.54%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 157, Loss: 0.1820, Valid: 71.11%, Test: 80.77%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 157, Loss: 0.1820, Valid: 72.54%, Test: 93.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 158, Loss: 0.1829, Valid: 65.69%, Test: 58.56%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 158, Loss: 0.1829, Valid: 70.88%, Test: 89.45%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 158, Loss: 0.1829, Valid: 72.44%, Test: 94.94%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 159, Loss: 0.1824, Valid: 65.74%, Test: 71.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 159, Loss: 0.1824, Valid: 70.58%, Test: 91.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 159, Loss: 0.1824, Valid: 72.55%, Test: 95.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 160, Loss: 0.1815, Valid: 65.44%, Test: 50.93%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 160, Loss: 0.1815, Valid: 70.57%, Test: 89.73%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 160, Loss: 0.1815, Valid: 72.78%, Test: 95.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 161, Loss: 0.1811, Valid: 67.46%, Test: 60.74%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 161, Loss: 0.1811, Valid: 71.43%, Test: 91.26%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 161, Loss: 0.1811, Valid: 72.87%, Test: 95.59%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 162, Loss: 0.1815, Valid: 67.08%, Test: 65.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 162, Loss: 0.1815, Valid: 71.28%, Test: 91.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 162, Loss: 0.1815, Valid: 72.63%, Test: 95.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 163, Loss: 0.1816, Valid: 68.14%, Test: 53.10%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 163, Loss: 0.1816, Valid: 71.36%, Test: 83.63%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 163, Loss: 0.1816, Valid: 72.78%, Test: 95.06%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 164, Loss: 0.1801, Valid: 68.29%, Test: 70.19%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 164, Loss: 0.1801, Valid: 70.95%, Test: 89.74%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 164, Loss: 0.1801, Valid: 72.58%, Test: 95.26%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 165, Loss: 0.1820, Valid: 66.16%, Test: 77.90%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 165, Loss: 0.1820, Valid: 71.55%, Test: 91.81%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 165, Loss: 0.1820, Valid: 73.06%, Test: 95.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 166, Loss: 0.1799, Valid: 67.02%, Test: 51.44%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 166, Loss: 0.1799, Valid: 71.33%, Test: 89.77%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 166, Loss: 0.1799, Valid: 72.86%, Test: 95.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 167, Loss: 0.1799, Valid: 65.61%, Test: 57.43%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 167, Loss: 0.1799, Valid: 70.42%, Test: 88.81%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 167, Loss: 0.1799, Valid: 72.45%, Test: 95.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 168, Loss: 0.1805, Valid: 67.74%, Test: 80.82%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 168, Loss: 0.1805, Valid: 71.87%, Test: 92.91%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 168, Loss: 0.1805, Valid: 81.62%, Test: 96.41%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 169, Loss: 0.1806, Valid: 65.17%, Test: 70.20%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 169, Loss: 0.1806, Valid: 71.37%, Test: 92.43%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 169, Loss: 0.1806, Valid: 72.86%, Test: 96.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 170, Loss: 0.1808, Valid: 67.99%, Test: 70.34%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 170, Loss: 0.1808, Valid: 71.84%, Test: 90.44%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 170, Loss: 0.1808, Valid: 73.04%, Test: 95.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 171, Loss: 0.1800, Valid: 66.48%, Test: 64.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 171, Loss: 0.1800, Valid: 70.79%, Test: 90.22%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 171, Loss: 0.1800, Valid: 72.60%, Test: 95.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 172, Loss: 0.1797, Valid: 67.36%, Test: 84.23%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 172, Loss: 0.1797, Valid: 71.70%, Test: 91.84%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 172, Loss: 0.1797, Valid: 73.23%, Test: 95.88%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 173, Loss: 0.1791, Valid: 67.91%, Test: 66.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 173, Loss: 0.1791, Valid: 71.79%, Test: 89.96%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 173, Loss: 0.1791, Valid: 72.98%, Test: 95.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 174, Loss: 0.1790, Valid: 64.34%, Test: 58.74%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 174, Loss: 0.1790, Valid: 70.94%, Test: 87.31%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 174, Loss: 0.1790, Valid: 72.71%, Test: 95.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 175, Loss: 0.1797, Valid: 66.92%, Test: 72.59%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 175, Loss: 0.1797, Valid: 71.73%, Test: 92.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 175, Loss: 0.1797, Valid: 77.68%, Test: 96.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 176, Loss: 0.1794, Valid: 67.28%, Test: 68.18%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 176, Loss: 0.1794, Valid: 71.61%, Test: 87.71%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 176, Loss: 0.1794, Valid: 73.04%, Test: 96.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 177, Loss: 0.1788, Valid: 65.55%, Test: 45.31%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 177, Loss: 0.1788, Valid: 71.42%, Test: 85.41%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 177, Loss: 0.1788, Valid: 72.91%, Test: 94.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 178, Loss: 0.1804, Valid: 65.85%, Test: 62.68%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 178, Loss: 0.1804, Valid: 71.59%, Test: 90.04%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 178, Loss: 0.1804, Valid: 72.98%, Test: 95.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 179, Loss: 0.1781, Valid: 66.40%, Test: 69.90%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 179, Loss: 0.1781, Valid: 71.94%, Test: 93.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 179, Loss: 0.1781, Valid: 74.04%, Test: 96.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 180, Loss: 0.1793, Valid: 65.13%, Test: 69.66%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 180, Loss: 0.1793, Valid: 71.95%, Test: 90.97%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 180, Loss: 0.1793, Valid: 73.25%, Test: 96.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 181, Loss: 0.1789, Valid: 68.56%, Test: 74.91%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 181, Loss: 0.1789, Valid: 71.96%, Test: 93.86%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 181, Loss: 0.1789, Valid: 87.77%, Test: 96.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 182, Loss: 0.1800, Valid: 68.23%, Test: 49.59%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 182, Loss: 0.1800, Valid: 71.81%, Test: 90.11%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 182, Loss: 0.1800, Valid: 73.27%, Test: 96.43%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 183, Loss: 0.1784, Valid: 68.53%, Test: 79.42%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 183, Loss: 0.1784, Valid: 72.11%, Test: 93.61%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 183, Loss: 0.1784, Valid: 74.49%, Test: 96.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 184, Loss: 0.1785, Valid: 67.09%, Test: 77.62%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 184, Loss: 0.1785, Valid: 71.69%, Test: 92.79%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 184, Loss: 0.1785, Valid: 73.20%, Test: 96.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 185, Loss: 0.1786, Valid: 68.40%, Test: 64.53%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 185, Loss: 0.1786, Valid: 72.17%, Test: 90.66%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 185, Loss: 0.1786, Valid: 73.15%, Test: 96.60%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 186, Loss: 0.1771, Valid: 67.97%, Test: 56.81%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 186, Loss: 0.1771, Valid: 71.97%, Test: 91.59%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 186, Loss: 0.1771, Valid: 73.31%, Test: 96.10%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 187, Loss: 0.1784, Valid: 67.81%, Test: 52.03%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 187, Loss: 0.1784, Valid: 72.00%, Test: 92.09%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 187, Loss: 0.1784, Valid: 73.30%, Test: 96.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 188, Loss: 0.1767, Valid: 67.30%, Test: 73.46%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 188, Loss: 0.1767, Valid: 72.13%, Test: 92.59%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 188, Loss: 0.1767, Valid: 74.40%, Test: 96.89%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 189, Loss: 0.1769, Valid: 65.80%, Test: 70.42%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 189, Loss: 0.1769, Valid: 72.21%, Test: 93.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 189, Loss: 0.1769, Valid: 85.25%, Test: 97.01%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 190, Loss: 0.1782, Valid: 67.99%, Test: 83.67%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 190, Loss: 0.1782, Valid: 72.13%, Test: 94.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 190, Loss: 0.1782, Valid: 74.26%, Test: 97.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 191, Loss: 0.1789, Valid: 66.38%, Test: 64.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 191, Loss: 0.1789, Valid: 71.83%, Test: 91.88%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 191, Loss: 0.1789, Valid: 73.03%, Test: 96.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 192, Loss: 0.1780, Valid: 68.29%, Test: 50.32%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 192, Loss: 0.1780, Valid: 71.86%, Test: 89.75%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 192, Loss: 0.1780, Valid: 73.18%, Test: 96.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 193, Loss: 0.1772, Valid: 67.61%, Test: 69.70%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 193, Loss: 0.1772, Valid: 72.10%, Test: 94.77%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 193, Loss: 0.1772, Valid: 73.28%, Test: 97.12%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 194, Loss: 0.1770, Valid: 68.55%, Test: 74.70%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 194, Loss: 0.1770, Valid: 71.74%, Test: 94.01%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 194, Loss: 0.1770, Valid: 73.29%, Test: 96.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 195, Loss: 0.1778, Valid: 68.78%, Test: 67.97%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 195, Loss: 0.1778, Valid: 71.74%, Test: 93.17%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 195, Loss: 0.1778, Valid: 73.39%, Test: 96.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 196, Loss: 0.1769, Valid: 68.00%, Test: 81.34%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 196, Loss: 0.1769, Valid: 72.26%, Test: 93.76%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 196, Loss: 0.1769, Valid: 82.39%, Test: 96.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 197, Loss: 0.1754, Valid: 67.65%, Test: 65.44%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 197, Loss: 0.1754, Valid: 71.97%, Test: 91.29%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 197, Loss: 0.1754, Valid: 75.62%, Test: 96.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 198, Loss: 0.1751, Valid: 68.24%, Test: 68.82%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 198, Loss: 0.1751, Valid: 72.18%, Test: 93.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 198, Loss: 0.1751, Valid: 73.36%, Test: 97.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 199, Loss: 0.1766, Valid: 68.46%, Test: 75.62%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 199, Loss: 0.1766, Valid: 72.28%, Test: 94.55%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 199, Loss: 0.1766, Valid: 93.42%, Test: 97.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 200, Loss: 0.1764, Valid: 68.83%, Test: 81.26%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 200, Loss: 0.1764, Valid: 72.34%, Test: 94.69%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 200, Loss: 0.1764, Valid: 74.95%, Test: 97.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 201, Loss: 0.1760, Valid: 66.01%, Test: 69.07%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 201, Loss: 0.1760, Valid: 71.96%, Test: 93.01%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 201, Loss: 0.1760, Valid: 73.54%, Test: 97.17%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 202, Loss: 0.1760, Valid: 66.75%, Test: 62.75%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 202, Loss: 0.1760, Valid: 72.45%, Test: 93.52%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 202, Loss: 0.1760, Valid: 80.93%, Test: 97.43%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 203, Loss: 0.1750, Valid: 68.80%, Test: 83.20%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 203, Loss: 0.1750, Valid: 72.59%, Test: 95.21%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 203, Loss: 0.1750, Valid: 83.63%, Test: 97.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 204, Loss: 0.1750, Valid: 69.16%, Test: 75.12%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 204, Loss: 0.1750, Valid: 72.66%, Test: 94.58%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 204, Loss: 0.1750, Valid: 76.81%, Test: 97.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 205, Loss: 0.1754, Valid: 69.52%, Test: 78.59%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 205, Loss: 0.1754, Valid: 72.67%, Test: 94.94%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 205, Loss: 0.1754, Valid: 84.77%, Test: 97.29%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 206, Loss: 0.1751, Valid: 68.97%, Test: 73.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 206, Loss: 0.1751, Valid: 72.73%, Test: 93.92%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 206, Loss: 0.1751, Valid: 86.79%, Test: 97.29%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 207, Loss: 0.1759, Valid: 66.89%, Test: 84.71%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 207, Loss: 0.1759, Valid: 71.72%, Test: 95.30%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 207, Loss: 0.1759, Valid: 82.15%, Test: 97.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 208, Loss: 0.1739, Valid: 67.32%, Test: 82.70%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 208, Loss: 0.1739, Valid: 72.48%, Test: 94.74%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 208, Loss: 0.1739, Valid: 94.21%, Test: 97.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 209, Loss: 0.1759, Valid: 68.37%, Test: 77.07%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 209, Loss: 0.1759, Valid: 71.99%, Test: 93.47%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 209, Loss: 0.1759, Valid: 73.58%, Test: 97.33%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 210, Loss: 0.1750, Valid: 70.02%, Test: 73.46%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 210, Loss: 0.1750, Valid: 72.23%, Test: 93.95%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 210, Loss: 0.1750, Valid: 73.43%, Test: 97.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 211, Loss: 0.1738, Valid: 67.93%, Test: 73.56%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 211, Loss: 0.1738, Valid: 72.28%, Test: 93.83%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 211, Loss: 0.1738, Valid: 74.32%, Test: 97.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 212, Loss: 0.1754, Valid: 68.33%, Test: 68.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 212, Loss: 0.1754, Valid: 72.46%, Test: 94.37%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 212, Loss: 0.1754, Valid: 73.61%, Test: 97.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 213, Loss: 0.1748, Valid: 68.81%, Test: 64.68%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 213, Loss: 0.1748, Valid: 72.47%, Test: 91.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 213, Loss: 0.1748, Valid: 73.42%, Test: 97.49%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 214, Loss: 0.1730, Valid: 68.59%, Test: 64.23%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 214, Loss: 0.1730, Valid: 72.38%, Test: 91.82%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 214, Loss: 0.1730, Valid: 73.44%, Test: 97.36%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 215, Loss: 0.1743, Valid: 67.72%, Test: 74.35%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 215, Loss: 0.1743, Valid: 72.88%, Test: 93.16%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 215, Loss: 0.1743, Valid: 75.50%, Test: 97.19%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 216, Loss: 0.1743, Valid: 64.47%, Test: 77.49%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 216, Loss: 0.1743, Valid: 72.26%, Test: 93.64%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 216, Loss: 0.1743, Valid: 73.57%, Test: 97.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 217, Loss: 0.1745, Valid: 65.07%, Test: 72.07%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 217, Loss: 0.1745, Valid: 72.54%, Test: 93.03%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 217, Loss: 0.1745, Valid: 74.92%, Test: 97.37%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 218, Loss: 0.1737, Valid: 68.47%, Test: 61.11%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 218, Loss: 0.1737, Valid: 72.74%, Test: 93.86%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 218, Loss: 0.1737, Valid: 75.52%, Test: 97.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 219, Loss: 0.1749, Valid: 69.48%, Test: 75.40%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 219, Loss: 0.1749, Valid: 72.92%, Test: 94.95%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 219, Loss: 0.1749, Valid: 87.95%, Test: 97.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 220, Loss: 0.1732, Valid: 68.99%, Test: 71.50%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 220, Loss: 0.1732, Valid: 72.70%, Test: 94.74%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 220, Loss: 0.1732, Valid: 91.58%, Test: 97.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 221, Loss: 0.1739, Valid: 68.67%, Test: 65.85%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 221, Loss: 0.1739, Valid: 72.46%, Test: 94.43%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 221, Loss: 0.1739, Valid: 74.10%, Test: 97.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 222, Loss: 0.1725, Valid: 69.53%, Test: 87.64%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 222, Loss: 0.1725, Valid: 72.75%, Test: 95.51%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 222, Loss: 0.1725, Valid: 91.16%, Test: 97.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 223, Loss: 0.1737, Valid: 67.49%, Test: 80.54%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 223, Loss: 0.1737, Valid: 71.84%, Test: 95.18%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 223, Loss: 0.1737, Valid: 77.11%, Test: 97.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 224, Loss: 0.1743, Valid: 68.50%, Test: 64.36%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 224, Loss: 0.1743, Valid: 72.68%, Test: 95.39%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 224, Loss: 0.1743, Valid: 92.73%, Test: 97.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 225, Loss: 0.1742, Valid: 70.00%, Test: 72.55%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 225, Loss: 0.1742, Valid: 72.84%, Test: 95.28%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 225, Loss: 0.1742, Valid: 92.11%, Test: 97.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 226, Loss: 0.1729, Valid: 68.59%, Test: 85.34%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 226, Loss: 0.1729, Valid: 72.73%, Test: 96.63%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 226, Loss: 0.1729, Valid: 88.31%, Test: 97.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 227, Loss: 0.1716, Valid: 69.53%, Test: 82.21%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 227, Loss: 0.1716, Valid: 72.87%, Test: 95.58%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 227, Loss: 0.1716, Valid: 90.20%, Test: 97.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 228, Loss: 0.1741, Valid: 69.38%, Test: 69.21%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 228, Loss: 0.1741, Valid: 72.55%, Test: 94.98%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 228, Loss: 0.1741, Valid: 92.67%, Test: 97.60%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 229, Loss: 0.1734, Valid: 69.91%, Test: 70.47%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 229, Loss: 0.1734, Valid: 72.64%, Test: 93.81%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 229, Loss: 0.1734, Valid: 86.57%, Test: 97.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 230, Loss: 0.1719, Valid: 69.95%, Test: 77.50%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 230, Loss: 0.1719, Valid: 72.67%, Test: 94.84%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 230, Loss: 0.1719, Valid: 89.58%, Test: 97.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 231, Loss: 0.1730, Valid: 68.71%, Test: 78.97%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 231, Loss: 0.1730, Valid: 72.28%, Test: 95.41%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 231, Loss: 0.1730, Valid: 79.28%, Test: 97.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 232, Loss: 0.1730, Valid: 64.75%, Test: 76.94%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 232, Loss: 0.1730, Valid: 72.32%, Test: 93.63%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 232, Loss: 0.1730, Valid: 73.72%, Test: 97.30%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 233, Loss: 0.1728, Valid: 68.56%, Test: 78.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 233, Loss: 0.1728, Valid: 72.50%, Test: 94.69%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 233, Loss: 0.1728, Valid: 86.21%, Test: 97.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 234, Loss: 0.1721, Valid: 67.99%, Test: 69.39%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 234, Loss: 0.1721, Valid: 72.45%, Test: 95.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 234, Loss: 0.1721, Valid: 74.77%, Test: 97.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 235, Loss: 0.1711, Valid: 69.65%, Test: 71.66%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 235, Loss: 0.1711, Valid: 72.98%, Test: 95.23%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 235, Loss: 0.1711, Valid: 90.16%, Test: 97.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 236, Loss: 0.1735, Valid: 68.72%, Test: 83.45%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 236, Loss: 0.1735, Valid: 72.62%, Test: 94.72%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 236, Loss: 0.1735, Valid: 76.63%, Test: 97.66%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 237, Loss: 0.1720, Valid: 70.67%, Test: 77.72%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 237, Loss: 0.1720, Valid: 73.04%, Test: 95.26%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 237, Loss: 0.1720, Valid: 91.41%, Test: 97.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 238, Loss: 0.1721, Valid: 70.39%, Test: 79.89%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 238, Loss: 0.1721, Valid: 73.02%, Test: 96.09%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 238, Loss: 0.1721, Valid: 95.85%, Test: 97.93%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 239, Loss: 0.1726, Valid: 69.39%, Test: 86.02%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 239, Loss: 0.1726, Valid: 72.89%, Test: 96.30%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 239, Loss: 0.1726, Valid: 95.39%, Test: 98.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 240, Loss: 0.1714, Valid: 70.17%, Test: 70.32%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 240, Loss: 0.1714, Valid: 72.75%, Test: 95.29%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 240, Loss: 0.1714, Valid: 89.75%, Test: 97.74%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 241, Loss: 0.1709, Valid: 68.96%, Test: 68.90%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 241, Loss: 0.1709, Valid: 72.93%, Test: 95.40%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 241, Loss: 0.1709, Valid: 76.14%, Test: 97.89%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 242, Loss: 0.1714, Valid: 69.15%, Test: 78.53%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 242, Loss: 0.1714, Valid: 72.47%, Test: 94.88%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 242, Loss: 0.1714, Valid: 74.58%, Test: 97.83%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 243, Loss: 0.1714, Valid: 69.36%, Test: 47.19%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 243, Loss: 0.1714, Valid: 72.93%, Test: 89.21%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 243, Loss: 0.1714, Valid: 73.96%, Test: 97.59%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 244, Loss: 0.1712, Valid: 70.85%, Test: 73.70%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 244, Loss: 0.1712, Valid: 73.16%, Test: 95.47%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 244, Loss: 0.1712, Valid: 88.15%, Test: 97.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 245, Loss: 0.1698, Valid: 69.42%, Test: 50.39%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 245, Loss: 0.1698, Valid: 72.45%, Test: 94.34%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 245, Loss: 0.1698, Valid: 74.02%, Test: 97.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 246, Loss: 0.1701, Valid: 70.83%, Test: 71.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 246, Loss: 0.1701, Valid: 72.88%, Test: 95.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 246, Loss: 0.1701, Valid: 95.12%, Test: 98.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 247, Loss: 0.1712, Valid: 70.01%, Test: 56.64%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 247, Loss: 0.1712, Valid: 73.05%, Test: 95.41%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 247, Loss: 0.1712, Valid: 88.85%, Test: 97.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 248, Loss: 0.1705, Valid: 70.63%, Test: 70.38%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 248, Loss: 0.1705, Valid: 72.86%, Test: 95.54%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 248, Loss: 0.1705, Valid: 85.28%, Test: 98.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 249, Loss: 0.1703, Valid: 70.30%, Test: 67.60%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 249, Loss: 0.1703, Valid: 72.59%, Test: 96.26%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 249, Loss: 0.1703, Valid: 94.07%, Test: 98.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 250, Loss: 0.1714, Valid: 69.88%, Test: 80.57%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 250, Loss: 0.1714, Valid: 72.86%, Test: 95.83%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 250, Loss: 0.1714, Valid: 92.26%, Test: 97.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 251, Loss: 0.1715, Valid: 69.99%, Test: 59.29%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 251, Loss: 0.1715, Valid: 73.10%, Test: 94.64%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 251, Loss: 0.1715, Valid: 78.00%, Test: 97.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 252, Loss: 0.1721, Valid: 70.94%, Test: 63.65%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 252, Loss: 0.1721, Valid: 73.18%, Test: 96.20%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 252, Loss: 0.1721, Valid: 95.20%, Test: 98.08%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 253, Loss: 0.1694, Valid: 69.85%, Test: 48.26%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 253, Loss: 0.1694, Valid: 72.83%, Test: 94.82%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 253, Loss: 0.1694, Valid: 78.68%, Test: 97.99%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 254, Loss: 0.1706, Valid: 70.79%, Test: 78.69%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 254, Loss: 0.1706, Valid: 73.12%, Test: 96.08%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 254, Loss: 0.1706, Valid: 92.71%, Test: 98.12%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 255, Loss: 0.1707, Valid: 69.27%, Test: 74.14%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 255, Loss: 0.1707, Valid: 72.96%, Test: 94.71%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 255, Loss: 0.1707, Valid: 91.37%, Test: 97.99%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 256, Loss: 0.1697, Valid: 70.22%, Test: 71.18%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 256, Loss: 0.1697, Valid: 73.12%, Test: 96.03%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 256, Loss: 0.1697, Valid: 97.84%, Test: 98.27%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 257, Loss: 0.1702, Valid: 67.40%, Test: 46.41%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 257, Loss: 0.1702, Valid: 73.03%, Test: 93.91%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 257, Loss: 0.1702, Valid: 89.83%, Test: 97.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 258, Loss: 0.1701, Valid: 70.13%, Test: 60.18%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 258, Loss: 0.1701, Valid: 73.09%, Test: 94.72%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 258, Loss: 0.1701, Valid: 87.03%, Test: 97.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 259, Loss: 0.1711, Valid: 69.91%, Test: 65.86%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 259, Loss: 0.1711, Valid: 72.98%, Test: 95.47%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 259, Loss: 0.1711, Valid: 93.48%, Test: 98.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 260, Loss: 0.1707, Valid: 69.39%, Test: 80.61%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 260, Loss: 0.1707, Valid: 72.77%, Test: 96.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 260, Loss: 0.1707, Valid: 93.18%, Test: 98.21%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 261, Loss: 0.1705, Valid: 67.83%, Test: 61.83%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 261, Loss: 0.1705, Valid: 72.80%, Test: 94.89%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 261, Loss: 0.1705, Valid: 75.96%, Test: 98.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 262, Loss: 0.1700, Valid: 70.67%, Test: 58.94%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 262, Loss: 0.1700, Valid: 73.36%, Test: 96.32%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 262, Loss: 0.1700, Valid: 95.10%, Test: 98.17%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 263, Loss: 0.1714, Valid: 70.25%, Test: 58.97%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 263, Loss: 0.1714, Valid: 73.29%, Test: 95.35%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 263, Loss: 0.1714, Valid: 89.51%, Test: 98.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 264, Loss: 0.1711, Valid: 71.33%, Test: 80.91%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 264, Loss: 0.1711, Valid: 74.20%, Test: 96.70%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 264, Loss: 0.1711, Valid: 98.40%, Test: 98.19%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 265, Loss: 0.1697, Valid: 70.36%, Test: 45.02%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 265, Loss: 0.1697, Valid: 73.33%, Test: 94.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 265, Loss: 0.1697, Valid: 94.80%, Test: 98.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 266, Loss: 0.1696, Valid: 71.20%, Test: 65.65%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 266, Loss: 0.1696, Valid: 74.38%, Test: 95.75%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 266, Loss: 0.1696, Valid: 97.83%, Test: 98.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 267, Loss: 0.1706, Valid: 71.50%, Test: 72.60%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 267, Loss: 0.1706, Valid: 73.61%, Test: 95.25%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 267, Loss: 0.1706, Valid: 97.45%, Test: 98.04%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 268, Loss: 0.1697, Valid: 71.83%, Test: 73.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 268, Loss: 0.1697, Valid: 76.11%, Test: 96.01%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 268, Loss: 0.1697, Valid: 98.27%, Test: 98.12%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 269, Loss: 0.1704, Valid: 67.67%, Test: 71.53%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 269, Loss: 0.1704, Valid: 72.96%, Test: 94.75%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 269, Loss: 0.1704, Valid: 94.21%, Test: 98.12%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 270, Loss: 0.1701, Valid: 68.39%, Test: 80.60%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 270, Loss: 0.1701, Valid: 72.96%, Test: 96.21%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 270, Loss: 0.1701, Valid: 92.07%, Test: 98.04%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 271, Loss: 0.1703, Valid: 69.69%, Test: 82.83%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 271, Loss: 0.1703, Valid: 73.22%, Test: 96.07%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 271, Loss: 0.1703, Valid: 95.45%, Test: 98.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 272, Loss: 0.1697, Valid: 70.40%, Test: 72.88%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 272, Loss: 0.1697, Valid: 73.44%, Test: 96.19%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 272, Loss: 0.1697, Valid: 95.45%, Test: 98.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 273, Loss: 0.1685, Valid: 70.27%, Test: 82.67%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 273, Loss: 0.1685, Valid: 73.04%, Test: 96.79%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 273, Loss: 0.1685, Valid: 95.04%, Test: 98.22%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 274, Loss: 0.1686, Valid: 70.71%, Test: 64.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 274, Loss: 0.1686, Valid: 73.05%, Test: 93.88%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 274, Loss: 0.1686, Valid: 92.05%, Test: 98.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 275, Loss: 0.1690, Valid: 71.09%, Test: 46.53%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 275, Loss: 0.1690, Valid: 73.49%, Test: 94.05%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 275, Loss: 0.1690, Valid: 94.66%, Test: 98.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 276, Loss: 0.1698, Valid: 70.71%, Test: 65.38%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 276, Loss: 0.1698, Valid: 73.28%, Test: 95.45%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 276, Loss: 0.1698, Valid: 75.80%, Test: 98.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 277, Loss: 0.1691, Valid: 71.09%, Test: 75.67%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 277, Loss: 0.1691, Valid: 73.23%, Test: 96.42%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 277, Loss: 0.1691, Valid: 96.09%, Test: 98.26%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 278, Loss: 0.1681, Valid: 71.74%, Test: 74.42%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 278, Loss: 0.1681, Valid: 73.54%, Test: 95.88%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 278, Loss: 0.1681, Valid: 97.44%, Test: 98.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 279, Loss: 0.1678, Valid: 71.03%, Test: 75.87%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 279, Loss: 0.1678, Valid: 73.38%, Test: 96.54%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 279, Loss: 0.1678, Valid: 94.21%, Test: 98.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 280, Loss: 0.1695, Valid: 71.26%, Test: 60.94%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 280, Loss: 0.1695, Valid: 73.58%, Test: 94.30%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 280, Loss: 0.1695, Valid: 94.69%, Test: 98.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 281, Loss: 0.1682, Valid: 70.83%, Test: 73.48%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 281, Loss: 0.1682, Valid: 73.23%, Test: 96.70%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 281, Loss: 0.1682, Valid: 97.58%, Test: 98.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 282, Loss: 0.1687, Valid: 71.61%, Test: 86.79%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 282, Loss: 0.1687, Valid: 82.18%, Test: 96.77%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 282, Loss: 0.1687, Valid: 98.05%, Test: 98.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 283, Loss: 0.1692, Valid: 71.55%, Test: 79.62%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 283, Loss: 0.1692, Valid: 73.58%, Test: 96.02%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 283, Loss: 0.1692, Valid: 96.58%, Test: 98.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 284, Loss: 0.1681, Valid: 71.45%, Test: 73.65%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 284, Loss: 0.1681, Valid: 73.36%, Test: 94.76%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 284, Loss: 0.1681, Valid: 97.20%, Test: 98.36%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 285, Loss: 0.1685, Valid: 71.70%, Test: 76.38%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 285, Loss: 0.1685, Valid: 73.91%, Test: 97.20%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 285, Loss: 0.1685, Valid: 98.08%, Test: 98.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 286, Loss: 0.1691, Valid: 71.39%, Test: 67.66%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 286, Loss: 0.1691, Valid: 76.71%, Test: 96.32%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 286, Loss: 0.1691, Valid: 97.52%, Test: 98.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 287, Loss: 0.1681, Valid: 71.75%, Test: 59.81%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 287, Loss: 0.1681, Valid: 73.60%, Test: 96.98%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 287, Loss: 0.1681, Valid: 96.12%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 288, Loss: 0.1676, Valid: 70.06%, Test: 70.64%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 288, Loss: 0.1676, Valid: 73.16%, Test: 95.48%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 288, Loss: 0.1676, Valid: 92.23%, Test: 98.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 289, Loss: 0.1699, Valid: 70.12%, Test: 69.27%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 289, Loss: 0.1699, Valid: 73.24%, Test: 95.18%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 289, Loss: 0.1699, Valid: 97.33%, Test: 98.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 290, Loss: 0.1695, Valid: 71.86%, Test: 63.19%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 290, Loss: 0.1695, Valid: 85.18%, Test: 96.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 290, Loss: 0.1695, Valid: 98.41%, Test: 98.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 291, Loss: 0.1689, Valid: 70.99%, Test: 50.54%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 291, Loss: 0.1689, Valid: 73.28%, Test: 95.86%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 291, Loss: 0.1689, Valid: 96.16%, Test: 98.19%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 292, Loss: 0.1683, Valid: 71.58%, Test: 70.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 292, Loss: 0.1683, Valid: 79.32%, Test: 95.71%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 292, Loss: 0.1683, Valid: 98.23%, Test: 98.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 293, Loss: 0.1673, Valid: 69.86%, Test: 71.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 293, Loss: 0.1673, Valid: 73.54%, Test: 96.35%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 293, Loss: 0.1673, Valid: 97.99%, Test: 98.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 294, Loss: 0.1676, Valid: 70.60%, Test: 70.12%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 294, Loss: 0.1676, Valid: 84.70%, Test: 96.76%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 294, Loss: 0.1676, Valid: 98.39%, Test: 98.55%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 295, Loss: 0.1664, Valid: 71.09%, Test: 69.38%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 295, Loss: 0.1664, Valid: 78.73%, Test: 95.75%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 295, Loss: 0.1664, Valid: 98.36%, Test: 98.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 296, Loss: 0.1672, Valid: 69.08%, Test: 66.03%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 296, Loss: 0.1672, Valid: 73.49%, Test: 96.59%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 296, Loss: 0.1672, Valid: 95.92%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 297, Loss: 0.1676, Valid: 71.34%, Test: 74.06%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 297, Loss: 0.1676, Valid: 73.51%, Test: 96.22%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 297, Loss: 0.1676, Valid: 97.51%, Test: 98.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 298, Loss: 0.1675, Valid: 69.57%, Test: 78.82%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 298, Loss: 0.1675, Valid: 73.80%, Test: 97.19%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 298, Loss: 0.1675, Valid: 97.46%, Test: 98.37%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 299, Loss: 0.1680, Valid: 71.04%, Test: 58.04%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 299, Loss: 0.1680, Valid: 73.47%, Test: 94.33%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 299, Loss: 0.1680, Valid: 97.25%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 300, Loss: 0.1685, Valid: 70.54%, Test: 75.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 300, Loss: 0.1685, Valid: 73.39%, Test: 95.86%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 300, Loss: 0.1685, Valid: 97.60%, Test: 98.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 301, Loss: 0.1686, Valid: 69.08%, Test: 50.59%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 301, Loss: 0.1686, Valid: 73.05%, Test: 92.92%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 301, Loss: 0.1686, Valid: 74.60%, Test: 98.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 302, Loss: 0.1689, Valid: 70.12%, Test: 72.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 302, Loss: 0.1689, Valid: 73.11%, Test: 94.90%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 302, Loss: 0.1689, Valid: 94.96%, Test: 98.42%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 303, Loss: 0.1676, Valid: 71.21%, Test: 64.01%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 303, Loss: 0.1676, Valid: 73.38%, Test: 95.42%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 303, Loss: 0.1676, Valid: 78.88%, Test: 98.37%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 304, Loss: 0.1687, Valid: 70.99%, Test: 65.17%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 304, Loss: 0.1687, Valid: 74.90%, Test: 95.90%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 304, Loss: 0.1687, Valid: 98.09%, Test: 98.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 305, Loss: 0.1673, Valid: 71.36%, Test: 73.25%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 305, Loss: 0.1673, Valid: 81.87%, Test: 97.22%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 305, Loss: 0.1673, Valid: 98.20%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 306, Loss: 0.1672, Valid: 70.15%, Test: 73.82%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 306, Loss: 0.1672, Valid: 81.71%, Test: 97.04%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 306, Loss: 0.1672, Valid: 98.59%, Test: 98.59%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 307, Loss: 0.1683, Valid: 69.94%, Test: 73.83%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 307, Loss: 0.1683, Valid: 73.42%, Test: 96.33%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 307, Loss: 0.1683, Valid: 97.30%, Test: 98.39%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 308, Loss: 0.1682, Valid: 71.55%, Test: 62.47%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 308, Loss: 0.1682, Valid: 76.84%, Test: 95.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 308, Loss: 0.1682, Valid: 98.14%, Test: 98.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 309, Loss: 0.1674, Valid: 70.06%, Test: 72.45%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 309, Loss: 0.1674, Valid: 73.87%, Test: 96.83%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 309, Loss: 0.1674, Valid: 98.52%, Test: 98.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 310, Loss: 0.1677, Valid: 70.95%, Test: 64.19%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 310, Loss: 0.1677, Valid: 74.14%, Test: 96.10%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 310, Loss: 0.1677, Valid: 98.15%, Test: 98.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 311, Loss: 0.1672, Valid: 69.94%, Test: 68.22%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 311, Loss: 0.1672, Valid: 74.00%, Test: 95.71%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 311, Loss: 0.1672, Valid: 97.91%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 312, Loss: 0.1674, Valid: 71.19%, Test: 64.49%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 312, Loss: 0.1674, Valid: 73.58%, Test: 96.60%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 312, Loss: 0.1674, Valid: 97.32%, Test: 98.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 313, Loss: 0.1676, Valid: 69.82%, Test: 65.89%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 313, Loss: 0.1676, Valid: 73.89%, Test: 96.25%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 313, Loss: 0.1676, Valid: 97.71%, Test: 98.60%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 314, Loss: 0.1662, Valid: 69.24%, Test: 48.97%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 314, Loss: 0.1662, Valid: 73.16%, Test: 92.23%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 314, Loss: 0.1662, Valid: 92.33%, Test: 98.22%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 315, Loss: 0.1669, Valid: 71.45%, Test: 61.46%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 315, Loss: 0.1669, Valid: 73.63%, Test: 96.14%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 315, Loss: 0.1669, Valid: 97.99%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 316, Loss: 0.1676, Valid: 72.21%, Test: 66.91%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 316, Loss: 0.1676, Valid: 88.63%, Test: 96.84%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 316, Loss: 0.1676, Valid: 98.65%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 317, Loss: 0.1666, Valid: 72.31%, Test: 76.86%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 317, Loss: 0.1666, Valid: 90.95%, Test: 97.42%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 317, Loss: 0.1666, Valid: 98.68%, Test: 98.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 318, Loss: 0.1666, Valid: 71.04%, Test: 63.04%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 318, Loss: 0.1666, Valid: 74.39%, Test: 96.73%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 318, Loss: 0.1666, Valid: 98.38%, Test: 98.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 319, Loss: 0.1663, Valid: 71.29%, Test: 66.77%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 319, Loss: 0.1663, Valid: 74.00%, Test: 96.68%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 319, Loss: 0.1663, Valid: 98.52%, Test: 98.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 320, Loss: 0.1660, Valid: 72.14%, Test: 70.16%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 320, Loss: 0.1660, Valid: 79.15%, Test: 96.96%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 320, Loss: 0.1660, Valid: 98.38%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 321, Loss: 0.1664, Valid: 71.13%, Test: 51.62%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 321, Loss: 0.1664, Valid: 73.55%, Test: 96.66%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 321, Loss: 0.1664, Valid: 94.96%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 322, Loss: 0.1668, Valid: 71.52%, Test: 60.83%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 322, Loss: 0.1668, Valid: 73.74%, Test: 96.46%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 322, Loss: 0.1668, Valid: 97.27%, Test: 98.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 323, Loss: 0.1678, Valid: 70.71%, Test: 41.13%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 323, Loss: 0.1678, Valid: 73.45%, Test: 94.15%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 323, Loss: 0.1678, Valid: 94.72%, Test: 98.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 324, Loss: 0.1684, Valid: 71.50%, Test: 70.57%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 324, Loss: 0.1684, Valid: 73.43%, Test: 96.10%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 324, Loss: 0.1684, Valid: 97.13%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 325, Loss: 0.1668, Valid: 71.34%, Test: 67.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 325, Loss: 0.1668, Valid: 74.90%, Test: 95.90%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 325, Loss: 0.1668, Valid: 98.24%, Test: 98.22%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 326, Loss: 0.1664, Valid: 70.68%, Test: 42.59%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 326, Loss: 0.1664, Valid: 73.63%, Test: 91.94%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 326, Loss: 0.1664, Valid: 96.97%, Test: 98.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 327, Loss: 0.1665, Valid: 70.99%, Test: 64.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 327, Loss: 0.1665, Valid: 77.53%, Test: 96.16%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 327, Loss: 0.1665, Valid: 98.56%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 328, Loss: 0.1675, Valid: 69.76%, Test: 52.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 328, Loss: 0.1675, Valid: 73.49%, Test: 93.91%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 328, Loss: 0.1675, Valid: 97.09%, Test: 98.17%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 329, Loss: 0.1661, Valid: 71.91%, Test: 61.23%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 329, Loss: 0.1661, Valid: 74.82%, Test: 96.66%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 329, Loss: 0.1661, Valid: 97.71%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 330, Loss: 0.1662, Valid: 70.48%, Test: 64.70%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 330, Loss: 0.1662, Valid: 73.55%, Test: 95.45%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 330, Loss: 0.1662, Valid: 96.96%, Test: 98.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 331, Loss: 0.1669, Valid: 70.22%, Test: 69.77%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 331, Loss: 0.1669, Valid: 73.48%, Test: 96.79%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 331, Loss: 0.1669, Valid: 96.10%, Test: 98.55%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 332, Loss: 0.1674, Valid: 71.84%, Test: 78.12%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 332, Loss: 0.1674, Valid: 73.35%, Test: 97.48%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 332, Loss: 0.1674, Valid: 98.22%, Test: 98.59%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 333, Loss: 0.1661, Valid: 71.02%, Test: 64.61%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 333, Loss: 0.1661, Valid: 73.54%, Test: 95.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 333, Loss: 0.1661, Valid: 96.20%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 334, Loss: 0.1652, Valid: 70.18%, Test: 74.13%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 334, Loss: 0.1652, Valid: 74.19%, Test: 95.70%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 334, Loss: 0.1652, Valid: 98.43%, Test: 98.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 335, Loss: 0.1659, Valid: 71.99%, Test: 75.08%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 335, Loss: 0.1659, Valid: 78.64%, Test: 96.64%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 335, Loss: 0.1659, Valid: 98.65%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 336, Loss: 0.1665, Valid: 72.22%, Test: 60.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 336, Loss: 0.1665, Valid: 73.57%, Test: 95.63%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 336, Loss: 0.1665, Valid: 96.93%, Test: 98.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 337, Loss: 0.1656, Valid: 71.51%, Test: 68.86%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 337, Loss: 0.1656, Valid: 74.51%, Test: 96.50%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 337, Loss: 0.1656, Valid: 97.65%, Test: 98.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 338, Loss: 0.1667, Valid: 72.29%, Test: 63.76%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 338, Loss: 0.1667, Valid: 75.91%, Test: 96.16%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 338, Loss: 0.1667, Valid: 98.07%, Test: 98.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 339, Loss: 0.1663, Valid: 71.05%, Test: 67.36%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 339, Loss: 0.1663, Valid: 74.38%, Test: 96.60%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 339, Loss: 0.1663, Valid: 98.15%, Test: 98.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 340, Loss: 0.1662, Valid: 71.13%, Test: 66.02%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 340, Loss: 0.1662, Valid: 74.37%, Test: 96.68%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 340, Loss: 0.1662, Valid: 98.54%, Test: 98.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 341, Loss: 0.1655, Valid: 72.23%, Test: 70.21%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 341, Loss: 0.1655, Valid: 74.61%, Test: 96.88%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 341, Loss: 0.1655, Valid: 97.80%, Test: 98.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 342, Loss: 0.1662, Valid: 72.46%, Test: 78.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 342, Loss: 0.1662, Valid: 79.28%, Test: 97.41%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 342, Loss: 0.1662, Valid: 98.78%, Test: 98.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 343, Loss: 0.1652, Valid: 71.07%, Test: 67.38%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 343, Loss: 0.1652, Valid: 74.35%, Test: 97.14%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 343, Loss: 0.1652, Valid: 98.10%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 344, Loss: 0.1659, Valid: 72.44%, Test: 72.92%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 344, Loss: 0.1659, Valid: 86.34%, Test: 97.57%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 344, Loss: 0.1659, Valid: 98.72%, Test: 98.68%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 345, Loss: 0.1651, Valid: 71.39%, Test: 60.74%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 345, Loss: 0.1651, Valid: 73.53%, Test: 96.40%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 345, Loss: 0.1651, Valid: 96.51%, Test: 98.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 346, Loss: 0.1668, Valid: 71.92%, Test: 71.25%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 346, Loss: 0.1668, Valid: 80.55%, Test: 97.37%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 346, Loss: 0.1668, Valid: 98.73%, Test: 98.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 347, Loss: 0.1666, Valid: 71.34%, Test: 62.12%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 347, Loss: 0.1666, Valid: 74.28%, Test: 96.34%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 347, Loss: 0.1666, Valid: 98.05%, Test: 98.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 348, Loss: 0.1664, Valid: 71.84%, Test: 79.50%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 348, Loss: 0.1664, Valid: 88.45%, Test: 97.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 348, Loss: 0.1664, Valid: 98.69%, Test: 98.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 349, Loss: 0.1647, Valid: 71.94%, Test: 75.92%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 349, Loss: 0.1647, Valid: 92.32%, Test: 97.72%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 349, Loss: 0.1647, Valid: 98.84%, Test: 98.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 350, Loss: 0.1657, Valid: 72.36%, Test: 56.97%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 350, Loss: 0.1657, Valid: 83.80%, Test: 97.82%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 350, Loss: 0.1657, Valid: 98.64%, Test: 98.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 351, Loss: 0.1661, Valid: 71.53%, Test: 64.55%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 351, Loss: 0.1661, Valid: 79.45%, Test: 97.48%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 351, Loss: 0.1661, Valid: 98.25%, Test: 98.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 352, Loss: 0.1654, Valid: 71.40%, Test: 67.09%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 352, Loss: 0.1654, Valid: 73.62%, Test: 97.55%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 352, Loss: 0.1654, Valid: 97.20%, Test: 98.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 353, Loss: 0.1657, Valid: 69.21%, Test: 49.55%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 353, Loss: 0.1657, Valid: 73.30%, Test: 93.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 353, Loss: 0.1657, Valid: 89.85%, Test: 98.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 354, Loss: 0.1665, Valid: 71.82%, Test: 66.96%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 354, Loss: 0.1665, Valid: 75.77%, Test: 97.39%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 354, Loss: 0.1665, Valid: 98.84%, Test: 98.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 355, Loss: 0.1649, Valid: 71.51%, Test: 83.29%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 355, Loss: 0.1649, Valid: 87.87%, Test: 97.39%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 355, Loss: 0.1649, Valid: 98.70%, Test: 98.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 356, Loss: 0.1654, Valid: 72.38%, Test: 66.89%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 356, Loss: 0.1654, Valid: 75.38%, Test: 97.46%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 356, Loss: 0.1654, Valid: 98.12%, Test: 98.79%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 357, Loss: 0.1654, Valid: 72.16%, Test: 71.03%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 357, Loss: 0.1654, Valid: 79.16%, Test: 96.26%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 357, Loss: 0.1654, Valid: 98.47%, Test: 98.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 358, Loss: 0.1658, Valid: 72.57%, Test: 71.31%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 358, Loss: 0.1658, Valid: 88.14%, Test: 97.14%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 358, Loss: 0.1658, Valid: 98.81%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 359, Loss: 0.1647, Valid: 71.62%, Test: 41.30%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 359, Loss: 0.1647, Valid: 73.75%, Test: 94.35%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 359, Loss: 0.1647, Valid: 95.36%, Test: 98.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 360, Loss: 0.1646, Valid: 72.49%, Test: 81.48%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 360, Loss: 0.1646, Valid: 77.49%, Test: 96.64%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 360, Loss: 0.1646, Valid: 98.66%, Test: 98.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 361, Loss: 0.1647, Valid: 72.72%, Test: 70.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 361, Loss: 0.1647, Valid: 92.08%, Test: 97.21%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 361, Loss: 0.1647, Valid: 98.81%, Test: 98.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 362, Loss: 0.1658, Valid: 71.45%, Test: 78.26%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 362, Loss: 0.1658, Valid: 73.81%, Test: 97.37%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 362, Loss: 0.1658, Valid: 98.50%, Test: 98.74%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 363, Loss: 0.1649, Valid: 71.52%, Test: 83.40%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 363, Loss: 0.1649, Valid: 89.29%, Test: 97.42%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 363, Loss: 0.1649, Valid: 98.87%, Test: 98.74%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 364, Loss: 0.1642, Valid: 71.97%, Test: 74.64%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 364, Loss: 0.1642, Valid: 77.39%, Test: 96.03%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 364, Loss: 0.1642, Valid: 98.59%, Test: 98.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 365, Loss: 0.1655, Valid: 72.24%, Test: 72.12%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 365, Loss: 0.1655, Valid: 82.61%, Test: 97.08%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 365, Loss: 0.1655, Valid: 98.86%, Test: 98.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 366, Loss: 0.1643, Valid: 72.67%, Test: 75.63%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 366, Loss: 0.1643, Valid: 91.66%, Test: 97.63%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 366, Loss: 0.1643, Valid: 98.99%, Test: 98.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 367, Loss: 0.1660, Valid: 71.77%, Test: 71.98%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 367, Loss: 0.1660, Valid: 81.34%, Test: 97.16%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 367, Loss: 0.1660, Valid: 98.68%, Test: 98.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 368, Loss: 0.1654, Valid: 72.05%, Test: 69.78%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 368, Loss: 0.1654, Valid: 75.74%, Test: 97.04%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 368, Loss: 0.1654, Valid: 98.48%, Test: 98.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 369, Loss: 0.1655, Valid: 72.22%, Test: 58.47%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 369, Loss: 0.1655, Valid: 86.47%, Test: 97.09%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 369, Loss: 0.1655, Valid: 98.62%, Test: 98.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 370, Loss: 0.1656, Valid: 72.29%, Test: 55.90%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 370, Loss: 0.1656, Valid: 78.33%, Test: 95.98%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 370, Loss: 0.1656, Valid: 98.75%, Test: 98.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 371, Loss: 0.1651, Valid: 71.58%, Test: 48.84%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 371, Loss: 0.1651, Valid: 73.55%, Test: 96.50%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 371, Loss: 0.1651, Valid: 97.05%, Test: 98.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 372, Loss: 0.1642, Valid: 72.12%, Test: 66.67%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 372, Loss: 0.1642, Valid: 89.27%, Test: 97.44%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 372, Loss: 0.1642, Valid: 98.80%, Test: 98.83%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 373, Loss: 0.1643, Valid: 72.91%, Test: 64.28%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 373, Loss: 0.1643, Valid: 91.09%, Test: 97.13%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 373, Loss: 0.1643, Valid: 98.94%, Test: 98.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 374, Loss: 0.1649, Valid: 71.88%, Test: 81.69%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 374, Loss: 0.1649, Valid: 92.67%, Test: 96.68%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 374, Loss: 0.1649, Valid: 98.72%, Test: 98.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 375, Loss: 0.1659, Valid: 71.59%, Test: 57.32%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 375, Loss: 0.1659, Valid: 73.54%, Test: 96.85%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 375, Loss: 0.1659, Valid: 96.67%, Test: 98.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 376, Loss: 0.1647, Valid: 73.02%, Test: 84.36%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 376, Loss: 0.1647, Valid: 88.67%, Test: 97.73%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 376, Loss: 0.1647, Valid: 99.10%, Test: 98.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 377, Loss: 0.1649, Valid: 70.22%, Test: 57.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 377, Loss: 0.1649, Valid: 73.87%, Test: 95.69%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 377, Loss: 0.1649, Valid: 97.11%, Test: 98.90%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 378, Loss: 0.1637, Valid: 72.71%, Test: 55.63%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 378, Loss: 0.1637, Valid: 81.75%, Test: 96.72%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 378, Loss: 0.1637, Valid: 98.54%, Test: 98.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 379, Loss: 0.1647, Valid: 73.00%, Test: 72.33%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 379, Loss: 0.1647, Valid: 93.89%, Test: 97.32%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 379, Loss: 0.1647, Valid: 98.89%, Test: 98.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 380, Loss: 0.1655, Valid: 72.20%, Test: 70.60%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 380, Loss: 0.1655, Valid: 87.46%, Test: 96.92%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 380, Loss: 0.1655, Valid: 98.25%, Test: 98.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 381, Loss: 0.1653, Valid: 72.66%, Test: 53.55%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 381, Loss: 0.1653, Valid: 73.79%, Test: 93.75%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 381, Loss: 0.1653, Valid: 95.79%, Test: 98.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 382, Loss: 0.1641, Valid: 72.47%, Test: 71.17%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 382, Loss: 0.1641, Valid: 93.27%, Test: 97.02%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 382, Loss: 0.1641, Valid: 98.71%, Test: 98.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 383, Loss: 0.1644, Valid: 72.61%, Test: 77.05%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 383, Loss: 0.1644, Valid: 89.63%, Test: 96.22%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 383, Loss: 0.1644, Valid: 98.79%, Test: 98.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 384, Loss: 0.1638, Valid: 72.21%, Test: 66.37%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 384, Loss: 0.1638, Valid: 86.17%, Test: 96.95%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 384, Loss: 0.1638, Valid: 98.41%, Test: 98.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 385, Loss: 0.1646, Valid: 72.55%, Test: 70.27%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 385, Loss: 0.1646, Valid: 78.57%, Test: 95.63%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 385, Loss: 0.1646, Valid: 98.42%, Test: 98.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 386, Loss: 0.1640, Valid: 72.45%, Test: 64.32%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 386, Loss: 0.1640, Valid: 79.83%, Test: 97.45%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 386, Loss: 0.1640, Valid: 98.60%, Test: 98.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 387, Loss: 0.1645, Valid: 72.15%, Test: 58.34%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 387, Loss: 0.1645, Valid: 77.69%, Test: 95.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 387, Loss: 0.1645, Valid: 98.48%, Test: 98.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 388, Loss: 0.1643, Valid: 72.45%, Test: 77.86%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 388, Loss: 0.1643, Valid: 93.28%, Test: 97.84%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 388, Loss: 0.1643, Valid: 99.01%, Test: 98.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 389, Loss: 0.1651, Valid: 70.04%, Test: 36.80%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 389, Loss: 0.1651, Valid: 73.68%, Test: 92.47%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 389, Loss: 0.1651, Valid: 97.51%, Test: 98.60%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 390, Loss: 0.1639, Valid: 72.45%, Test: 83.95%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 390, Loss: 0.1639, Valid: 94.32%, Test: 97.24%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 390, Loss: 0.1639, Valid: 98.75%, Test: 98.66%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 391, Loss: 0.1642, Valid: 72.15%, Test: 67.97%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 391, Loss: 0.1642, Valid: 74.60%, Test: 97.04%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 391, Loss: 0.1642, Valid: 98.56%, Test: 98.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 392, Loss: 0.1641, Valid: 72.12%, Test: 73.06%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 392, Loss: 0.1641, Valid: 81.72%, Test: 97.53%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 392, Loss: 0.1641, Valid: 98.46%, Test: 98.88%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 393, Loss: 0.1637, Valid: 72.37%, Test: 78.92%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 393, Loss: 0.1637, Valid: 81.02%, Test: 97.50%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 393, Loss: 0.1637, Valid: 98.77%, Test: 98.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 394, Loss: 0.1631, Valid: 70.99%, Test: 73.87%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 394, Loss: 0.1631, Valid: 81.51%, Test: 97.40%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 394, Loss: 0.1631, Valid: 98.73%, Test: 98.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 395, Loss: 0.1637, Valid: 70.96%, Test: 73.37%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 395, Loss: 0.1637, Valid: 80.63%, Test: 97.46%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 395, Loss: 0.1637, Valid: 98.60%, Test: 98.88%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 396, Loss: 0.1643, Valid: 72.25%, Test: 85.57%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 396, Loss: 0.1643, Valid: 91.81%, Test: 97.54%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 396, Loss: 0.1643, Valid: 98.94%, Test: 98.89%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 397, Loss: 0.1644, Valid: 71.91%, Test: 84.24%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 397, Loss: 0.1644, Valid: 87.69%, Test: 97.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 397, Loss: 0.1644, Valid: 98.68%, Test: 98.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 398, Loss: 0.1644, Valid: 71.40%, Test: 69.00%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 398, Loss: 0.1644, Valid: 81.32%, Test: 97.46%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 398, Loss: 0.1644, Valid: 98.39%, Test: 98.91%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 399, Loss: 0.1621, Valid: 71.47%, Test: 67.69%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 399, Loss: 0.1621, Valid: 75.21%, Test: 97.27%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 399, Loss: 0.1621, Valid: 98.52%, Test: 98.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 01, Epoch: 400, Loss: 0.1651, Valid: 71.73%, Test: 76.61%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 400, Loss: 0.1651, Valid: 91.76%, Test: 97.94%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 400, Loss: 0.1651, Valid: 98.77%, Test: 98.83%\n",
      "---\n",
      "Hits@20\n",
      "Run 01:\n",
      "Highest Valid: 73.02\n",
      "   Final Test: 84.36\n",
      "Hits@50\n",
      "Run 01:\n",
      "Highest Valid: 94.32\n",
      "   Final Test: 97.24\n",
      "Hits@100\n",
      "Run 01:\n",
      "Highest Valid: 99.10\n",
      "   Final Test: 98.84\n",
      "Hits@20\n",
      "Run: 02, Epoch: 01, Loss: 1.3215, Valid: 2.78%, Test: 3.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 01, Loss: 1.3215, Valid: 4.69%, Test: 5.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 01, Loss: 1.3215, Valid: 6.66%, Test: 8.04%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 02, Loss: 0.9002, Valid: 2.89%, Test: 6.61%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 02, Loss: 0.9002, Valid: 5.22%, Test: 8.27%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 02, Loss: 0.9002, Valid: 7.93%, Test: 10.37%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 03, Loss: 0.8165, Valid: 3.54%, Test: 8.52%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 03, Loss: 0.8165, Valid: 6.52%, Test: 10.68%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 03, Loss: 0.8165, Valid: 9.45%, Test: 12.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 04, Loss: 0.7714, Valid: 3.19%, Test: 6.26%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 04, Loss: 0.7714, Valid: 5.97%, Test: 9.12%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 04, Loss: 0.7714, Valid: 9.13%, Test: 11.89%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.7168, Valid: 7.95%, Test: 9.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 05, Loss: 0.7168, Valid: 11.08%, Test: 12.64%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 05, Loss: 0.7168, Valid: 13.71%, Test: 17.36%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 06, Loss: 0.6647, Valid: 11.83%, Test: 12.66%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 06, Loss: 0.6647, Valid: 17.11%, Test: 20.46%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 06, Loss: 0.6647, Valid: 21.56%, Test: 24.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 07, Loss: 0.6195, Valid: 18.75%, Test: 16.41%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 07, Loss: 0.6195, Valid: 22.86%, Test: 24.02%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 07, Loss: 0.6195, Valid: 29.20%, Test: 29.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 08, Loss: 0.5832, Valid: 20.04%, Test: 11.39%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 08, Loss: 0.5832, Valid: 25.13%, Test: 16.86%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 08, Loss: 0.5832, Valid: 30.67%, Test: 26.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 09, Loss: 0.5612, Valid: 14.95%, Test: 9.46%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 09, Loss: 0.5612, Valid: 22.74%, Test: 15.88%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 09, Loss: 0.5612, Valid: 29.28%, Test: 26.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 10, Loss: 0.5363, Valid: 21.37%, Test: 11.29%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 10, Loss: 0.5363, Valid: 27.79%, Test: 18.91%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 10, Loss: 0.5363, Valid: 34.14%, Test: 28.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 11, Loss: 0.5152, Valid: 22.38%, Test: 16.67%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 11, Loss: 0.5152, Valid: 28.75%, Test: 28.70%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 11, Loss: 0.5152, Valid: 35.89%, Test: 34.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 12, Loss: 0.4938, Valid: 15.88%, Test: 18.78%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 12, Loss: 0.4938, Valid: 30.83%, Test: 30.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 12, Loss: 0.4938, Valid: 38.13%, Test: 37.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 13, Loss: 0.4766, Valid: 18.63%, Test: 16.80%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 13, Loss: 0.4766, Valid: 27.76%, Test: 26.72%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 13, Loss: 0.4766, Valid: 35.84%, Test: 36.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 14, Loss: 0.4607, Valid: 22.28%, Test: 20.14%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 14, Loss: 0.4607, Valid: 31.67%, Test: 32.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 14, Loss: 0.4607, Valid: 39.43%, Test: 42.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 15, Loss: 0.4458, Valid: 23.75%, Test: 14.79%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 15, Loss: 0.4458, Valid: 33.90%, Test: 31.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 15, Loss: 0.4458, Valid: 40.84%, Test: 43.31%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 16, Loss: 0.4330, Valid: 19.09%, Test: 12.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 16, Loss: 0.4330, Valid: 29.57%, Test: 28.61%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 16, Loss: 0.4330, Valid: 40.12%, Test: 39.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 17, Loss: 0.4183, Valid: 31.22%, Test: 30.21%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 17, Loss: 0.4183, Valid: 37.56%, Test: 41.91%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 17, Loss: 0.4183, Valid: 46.54%, Test: 49.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 18, Loss: 0.4099, Valid: 24.71%, Test: 20.45%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 18, Loss: 0.4099, Valid: 34.00%, Test: 31.39%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 18, Loss: 0.4099, Valid: 41.70%, Test: 42.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 19, Loss: 0.3976, Valid: 26.73%, Test: 25.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 19, Loss: 0.3976, Valid: 37.59%, Test: 39.15%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 19, Loss: 0.3976, Valid: 44.32%, Test: 50.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 20, Loss: 0.3850, Valid: 28.42%, Test: 29.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 20, Loss: 0.3850, Valid: 36.44%, Test: 39.95%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 20, Loss: 0.3850, Valid: 44.31%, Test: 49.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 21, Loss: 0.3797, Valid: 28.51%, Test: 19.25%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 21, Loss: 0.3797, Valid: 36.13%, Test: 32.91%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 21, Loss: 0.3797, Valid: 43.84%, Test: 44.10%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 22, Loss: 0.3687, Valid: 29.44%, Test: 19.25%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 22, Loss: 0.3687, Valid: 37.36%, Test: 33.20%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 22, Loss: 0.3687, Valid: 43.75%, Test: 44.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 23, Loss: 0.3645, Valid: 30.55%, Test: 24.87%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 23, Loss: 0.3645, Valid: 39.35%, Test: 38.09%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 23, Loss: 0.3645, Valid: 45.71%, Test: 48.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 24, Loss: 0.3555, Valid: 31.50%, Test: 23.23%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 24, Loss: 0.3555, Valid: 40.21%, Test: 35.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 24, Loss: 0.3555, Valid: 47.74%, Test: 46.79%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 25, Loss: 0.3459, Valid: 36.66%, Test: 23.27%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 25, Loss: 0.3459, Valid: 43.62%, Test: 35.23%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 25, Loss: 0.3459, Valid: 49.35%, Test: 47.30%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 26, Loss: 0.3436, Valid: 30.92%, Test: 25.40%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 26, Loss: 0.3436, Valid: 39.43%, Test: 35.18%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 26, Loss: 0.3436, Valid: 45.73%, Test: 48.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 27, Loss: 0.3356, Valid: 33.17%, Test: 22.39%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 27, Loss: 0.3356, Valid: 41.30%, Test: 32.27%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 27, Loss: 0.3356, Valid: 48.03%, Test: 43.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 28, Loss: 0.3287, Valid: 36.51%, Test: 19.05%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 28, Loss: 0.3287, Valid: 42.85%, Test: 30.56%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 28, Loss: 0.3287, Valid: 48.72%, Test: 42.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 29, Loss: 0.3228, Valid: 33.14%, Test: 22.18%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 29, Loss: 0.3228, Valid: 41.70%, Test: 32.88%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 29, Loss: 0.3228, Valid: 49.47%, Test: 45.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 30, Loss: 0.3197, Valid: 36.34%, Test: 19.98%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 30, Loss: 0.3197, Valid: 43.46%, Test: 30.78%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 30, Loss: 0.3197, Valid: 50.51%, Test: 42.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 31, Loss: 0.3122, Valid: 35.66%, Test: 19.67%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 31, Loss: 0.3122, Valid: 46.93%, Test: 32.66%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 31, Loss: 0.3122, Valid: 53.37%, Test: 44.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 32, Loss: 0.3074, Valid: 32.42%, Test: 19.09%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 32, Loss: 0.3074, Valid: 44.03%, Test: 33.08%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 32, Loss: 0.3074, Valid: 50.15%, Test: 44.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 33, Loss: 0.3045, Valid: 37.09%, Test: 17.01%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 33, Loss: 0.3045, Valid: 46.00%, Test: 27.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 33, Loss: 0.3045, Valid: 51.99%, Test: 40.66%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 34, Loss: 0.2993, Valid: 33.85%, Test: 15.90%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 34, Loss: 0.2993, Valid: 46.25%, Test: 26.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 34, Loss: 0.2993, Valid: 51.48%, Test: 40.66%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 35, Loss: 0.2959, Valid: 39.52%, Test: 13.25%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 35, Loss: 0.2959, Valid: 49.14%, Test: 27.33%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 35, Loss: 0.2959, Valid: 55.02%, Test: 38.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 36, Loss: 0.2897, Valid: 39.49%, Test: 16.93%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 36, Loss: 0.2897, Valid: 47.93%, Test: 28.26%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 36, Loss: 0.2897, Valid: 54.79%, Test: 42.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 37, Loss: 0.2853, Valid: 38.67%, Test: 17.42%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 37, Loss: 0.2853, Valid: 48.19%, Test: 28.23%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 37, Loss: 0.2853, Valid: 54.78%, Test: 40.31%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 38, Loss: 0.2842, Valid: 38.93%, Test: 19.51%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 38, Loss: 0.2842, Valid: 49.82%, Test: 31.70%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 38, Loss: 0.2842, Valid: 55.86%, Test: 43.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 39, Loss: 0.2795, Valid: 44.16%, Test: 13.75%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 39, Loss: 0.2795, Valid: 53.86%, Test: 28.65%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 39, Loss: 0.2795, Valid: 58.02%, Test: 41.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 40, Loss: 0.2762, Valid: 42.67%, Test: 13.74%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 40, Loss: 0.2762, Valid: 52.36%, Test: 29.42%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 40, Loss: 0.2762, Valid: 59.24%, Test: 39.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 41, Loss: 0.2714, Valid: 42.03%, Test: 15.97%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 41, Loss: 0.2714, Valid: 53.18%, Test: 30.48%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 41, Loss: 0.2714, Valid: 58.80%, Test: 45.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 42, Loss: 0.2694, Valid: 42.55%, Test: 17.03%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 42, Loss: 0.2694, Valid: 51.93%, Test: 28.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 42, Loss: 0.2694, Valid: 58.89%, Test: 48.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 43, Loss: 0.2673, Valid: 35.55%, Test: 13.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 43, Loss: 0.2673, Valid: 49.73%, Test: 28.22%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 43, Loss: 0.2673, Valid: 57.22%, Test: 44.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 44, Loss: 0.2655, Valid: 45.31%, Test: 15.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 44, Loss: 0.2655, Valid: 54.10%, Test: 31.66%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 44, Loss: 0.2655, Valid: 58.82%, Test: 47.59%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 45, Loss: 0.2597, Valid: 40.43%, Test: 15.29%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 45, Loss: 0.2597, Valid: 54.21%, Test: 29.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 45, Loss: 0.2597, Valid: 59.74%, Test: 47.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 46, Loss: 0.2593, Valid: 47.38%, Test: 19.71%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 46, Loss: 0.2593, Valid: 56.32%, Test: 31.76%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 46, Loss: 0.2593, Valid: 60.82%, Test: 51.98%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 47, Loss: 0.2575, Valid: 48.52%, Test: 17.07%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 47, Loss: 0.2575, Valid: 56.29%, Test: 32.82%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 47, Loss: 0.2575, Valid: 60.17%, Test: 52.88%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 48, Loss: 0.2531, Valid: 47.81%, Test: 17.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 48, Loss: 0.2531, Valid: 57.60%, Test: 31.76%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 48, Loss: 0.2531, Valid: 60.79%, Test: 50.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 49, Loss: 0.2511, Valid: 48.29%, Test: 19.27%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 49, Loss: 0.2511, Valid: 57.26%, Test: 33.67%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 49, Loss: 0.2511, Valid: 61.89%, Test: 48.04%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 50, Loss: 0.2489, Valid: 49.20%, Test: 18.85%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 50, Loss: 0.2489, Valid: 58.04%, Test: 39.03%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 50, Loss: 0.2489, Valid: 62.69%, Test: 62.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 51, Loss: 0.2486, Valid: 47.00%, Test: 20.66%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 51, Loss: 0.2486, Valid: 56.34%, Test: 39.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 51, Loss: 0.2486, Valid: 61.51%, Test: 58.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 52, Loss: 0.2464, Valid: 51.89%, Test: 24.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 52, Loss: 0.2464, Valid: 59.18%, Test: 45.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 52, Loss: 0.2464, Valid: 63.67%, Test: 66.04%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 53, Loss: 0.2439, Valid: 50.83%, Test: 17.82%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 53, Loss: 0.2439, Valid: 58.74%, Test: 34.31%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 53, Loss: 0.2439, Valid: 63.97%, Test: 50.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 54, Loss: 0.2430, Valid: 51.79%, Test: 20.15%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 54, Loss: 0.2430, Valid: 59.30%, Test: 37.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 54, Loss: 0.2430, Valid: 63.05%, Test: 58.93%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 55, Loss: 0.2408, Valid: 53.60%, Test: 22.73%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 55, Loss: 0.2408, Valid: 60.94%, Test: 42.80%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 55, Loss: 0.2408, Valid: 64.20%, Test: 63.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 56, Loss: 0.2399, Valid: 52.95%, Test: 25.41%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 56, Loss: 0.2399, Valid: 60.68%, Test: 47.45%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 56, Loss: 0.2399, Valid: 64.37%, Test: 67.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 57, Loss: 0.2372, Valid: 54.51%, Test: 26.18%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 57, Loss: 0.2372, Valid: 60.47%, Test: 47.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 57, Loss: 0.2372, Valid: 64.57%, Test: 68.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 58, Loss: 0.2357, Valid: 53.30%, Test: 27.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 58, Loss: 0.2357, Valid: 61.06%, Test: 52.90%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 58, Loss: 0.2357, Valid: 65.02%, Test: 75.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 59, Loss: 0.2346, Valid: 52.60%, Test: 16.67%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 59, Loss: 0.2346, Valid: 61.78%, Test: 37.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 59, Loss: 0.2346, Valid: 65.07%, Test: 64.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 60, Loss: 0.2313, Valid: 53.98%, Test: 16.22%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 60, Loss: 0.2313, Valid: 62.27%, Test: 44.53%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 60, Loss: 0.2313, Valid: 66.25%, Test: 71.55%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 61, Loss: 0.2308, Valid: 54.02%, Test: 23.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 61, Loss: 0.2308, Valid: 62.20%, Test: 48.10%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 61, Loss: 0.2308, Valid: 65.89%, Test: 72.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 62, Loss: 0.2291, Valid: 56.22%, Test: 22.64%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 62, Loss: 0.2291, Valid: 63.33%, Test: 56.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 62, Loss: 0.2291, Valid: 66.79%, Test: 78.98%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 63, Loss: 0.2265, Valid: 53.11%, Test: 19.49%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 63, Loss: 0.2265, Valid: 63.15%, Test: 53.62%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 63, Loss: 0.2265, Valid: 66.70%, Test: 74.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 64, Loss: 0.2282, Valid: 55.21%, Test: 25.83%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 64, Loss: 0.2282, Valid: 63.80%, Test: 56.39%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 64, Loss: 0.2282, Valid: 66.97%, Test: 80.37%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 65, Loss: 0.2260, Valid: 55.98%, Test: 12.92%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 65, Loss: 0.2260, Valid: 62.83%, Test: 46.88%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 65, Loss: 0.2260, Valid: 66.89%, Test: 73.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 66, Loss: 0.2240, Valid: 55.55%, Test: 18.85%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 66, Loss: 0.2240, Valid: 63.40%, Test: 58.05%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 66, Loss: 0.2240, Valid: 66.99%, Test: 79.01%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 67, Loss: 0.2245, Valid: 55.79%, Test: 25.55%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 67, Loss: 0.2245, Valid: 63.03%, Test: 68.01%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 67, Loss: 0.2245, Valid: 67.36%, Test: 79.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 68, Loss: 0.2227, Valid: 57.52%, Test: 28.62%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 68, Loss: 0.2227, Valid: 64.28%, Test: 68.16%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 68, Loss: 0.2227, Valid: 67.31%, Test: 80.55%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 69, Loss: 0.2218, Valid: 50.32%, Test: 19.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 69, Loss: 0.2218, Valid: 63.29%, Test: 59.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 69, Loss: 0.2218, Valid: 67.31%, Test: 81.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 70, Loss: 0.2196, Valid: 55.47%, Test: 20.11%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 70, Loss: 0.2196, Valid: 64.03%, Test: 51.04%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 70, Loss: 0.2196, Valid: 67.62%, Test: 78.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 71, Loss: 0.2204, Valid: 57.88%, Test: 23.22%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 71, Loss: 0.2204, Valid: 64.84%, Test: 55.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 71, Loss: 0.2204, Valid: 67.59%, Test: 80.19%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 72, Loss: 0.2195, Valid: 56.43%, Test: 23.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 72, Loss: 0.2195, Valid: 65.04%, Test: 70.64%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 72, Loss: 0.2195, Valid: 67.91%, Test: 81.27%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 73, Loss: 0.2171, Valid: 55.28%, Test: 22.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 73, Loss: 0.2171, Valid: 64.64%, Test: 63.25%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 73, Loss: 0.2171, Valid: 67.75%, Test: 82.06%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 74, Loss: 0.2150, Valid: 61.88%, Test: 14.81%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 74, Loss: 0.2150, Valid: 65.20%, Test: 71.99%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 74, Loss: 0.2150, Valid: 68.20%, Test: 84.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 75, Loss: 0.2146, Valid: 57.29%, Test: 22.13%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 75, Loss: 0.2146, Valid: 65.08%, Test: 60.84%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 75, Loss: 0.2146, Valid: 68.54%, Test: 83.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 76, Loss: 0.2133, Valid: 58.70%, Test: 36.99%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 76, Loss: 0.2133, Valid: 64.77%, Test: 71.76%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 76, Loss: 0.2133, Valid: 68.12%, Test: 83.12%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 77, Loss: 0.2128, Valid: 55.92%, Test: 36.40%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 77, Loss: 0.2128, Valid: 65.26%, Test: 69.11%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 77, Loss: 0.2128, Valid: 68.31%, Test: 84.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 78, Loss: 0.2108, Valid: 58.27%, Test: 20.82%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 78, Loss: 0.2108, Valid: 66.20%, Test: 69.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 78, Loss: 0.2108, Valid: 68.61%, Test: 85.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 79, Loss: 0.2114, Valid: 57.92%, Test: 34.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 79, Loss: 0.2114, Valid: 66.41%, Test: 74.86%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 79, Loss: 0.2114, Valid: 68.93%, Test: 86.94%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 80, Loss: 0.2116, Valid: 61.15%, Test: 29.52%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 80, Loss: 0.2116, Valid: 66.04%, Test: 72.86%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 80, Loss: 0.2116, Valid: 69.01%, Test: 86.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 81, Loss: 0.2095, Valid: 60.83%, Test: 31.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 81, Loss: 0.2095, Valid: 66.69%, Test: 73.82%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 81, Loss: 0.2095, Valid: 69.05%, Test: 87.21%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 82, Loss: 0.2098, Valid: 57.68%, Test: 17.13%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 82, Loss: 0.2098, Valid: 65.60%, Test: 72.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 82, Loss: 0.2098, Valid: 68.48%, Test: 85.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 83, Loss: 0.2099, Valid: 58.77%, Test: 24.76%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 83, Loss: 0.2099, Valid: 65.85%, Test: 65.54%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 83, Loss: 0.2099, Valid: 69.05%, Test: 85.60%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 84, Loss: 0.2064, Valid: 55.58%, Test: 23.32%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 84, Loss: 0.2064, Valid: 65.94%, Test: 60.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 84, Loss: 0.2064, Valid: 68.74%, Test: 84.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 85, Loss: 0.2071, Valid: 60.40%, Test: 23.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 85, Loss: 0.2071, Valid: 65.81%, Test: 65.68%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 85, Loss: 0.2071, Valid: 68.88%, Test: 86.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 86, Loss: 0.2073, Valid: 60.13%, Test: 20.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 86, Loss: 0.2073, Valid: 66.88%, Test: 55.15%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 86, Loss: 0.2073, Valid: 69.08%, Test: 87.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 87, Loss: 0.2053, Valid: 60.38%, Test: 29.73%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 87, Loss: 0.2053, Valid: 66.78%, Test: 75.54%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 87, Loss: 0.2053, Valid: 68.61%, Test: 87.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 88, Loss: 0.2047, Valid: 59.67%, Test: 27.12%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 88, Loss: 0.2047, Valid: 66.56%, Test: 65.55%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 88, Loss: 0.2047, Valid: 69.22%, Test: 86.74%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 89, Loss: 0.2049, Valid: 61.29%, Test: 26.91%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 89, Loss: 0.2049, Valid: 66.53%, Test: 67.42%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 89, Loss: 0.2049, Valid: 69.48%, Test: 86.07%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 90, Loss: 0.2026, Valid: 61.89%, Test: 33.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 90, Loss: 0.2026, Valid: 67.00%, Test: 73.41%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 90, Loss: 0.2026, Valid: 69.42%, Test: 86.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 91, Loss: 0.2054, Valid: 61.58%, Test: 45.66%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 91, Loss: 0.2054, Valid: 66.57%, Test: 76.59%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 91, Loss: 0.2054, Valid: 69.52%, Test: 87.94%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 92, Loss: 0.2017, Valid: 60.69%, Test: 26.34%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 92, Loss: 0.2017, Valid: 66.39%, Test: 77.87%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 92, Loss: 0.2017, Valid: 69.63%, Test: 88.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 93, Loss: 0.2033, Valid: 61.00%, Test: 47.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 93, Loss: 0.2033, Valid: 66.75%, Test: 82.22%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 93, Loss: 0.2033, Valid: 69.72%, Test: 89.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 94, Loss: 0.2034, Valid: 62.61%, Test: 47.21%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 94, Loss: 0.2034, Valid: 66.49%, Test: 78.98%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 94, Loss: 0.2034, Valid: 69.47%, Test: 89.04%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 95, Loss: 0.2017, Valid: 62.95%, Test: 34.56%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 95, Loss: 0.2017, Valid: 66.91%, Test: 80.35%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 95, Loss: 0.2017, Valid: 69.64%, Test: 89.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 96, Loss: 0.2005, Valid: 58.74%, Test: 37.55%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 96, Loss: 0.2005, Valid: 66.62%, Test: 65.33%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 96, Loss: 0.2005, Valid: 69.65%, Test: 84.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 97, Loss: 0.2010, Valid: 62.20%, Test: 36.11%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 97, Loss: 0.2010, Valid: 68.03%, Test: 76.26%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 97, Loss: 0.2010, Valid: 70.02%, Test: 88.92%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 98, Loss: 0.1992, Valid: 61.20%, Test: 37.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 98, Loss: 0.1992, Valid: 67.37%, Test: 76.76%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 98, Loss: 0.1992, Valid: 69.73%, Test: 88.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 99, Loss: 0.1988, Valid: 63.86%, Test: 39.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 99, Loss: 0.1988, Valid: 67.59%, Test: 79.20%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 99, Loss: 0.1988, Valid: 69.81%, Test: 88.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 100, Loss: 0.1970, Valid: 63.32%, Test: 38.29%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 100, Loss: 0.1970, Valid: 67.64%, Test: 84.83%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 100, Loss: 0.1970, Valid: 70.23%, Test: 90.66%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 101, Loss: 0.1978, Valid: 63.06%, Test: 29.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 101, Loss: 0.1978, Valid: 67.73%, Test: 81.94%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 101, Loss: 0.1978, Valid: 70.28%, Test: 90.74%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 102, Loss: 0.1971, Valid: 63.97%, Test: 38.18%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 102, Loss: 0.1971, Valid: 68.39%, Test: 82.45%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 102, Loss: 0.1971, Valid: 70.32%, Test: 90.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 103, Loss: 0.1972, Valid: 64.37%, Test: 34.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 103, Loss: 0.1972, Valid: 68.13%, Test: 82.45%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 103, Loss: 0.1972, Valid: 70.15%, Test: 90.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 104, Loss: 0.1961, Valid: 64.14%, Test: 37.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 104, Loss: 0.1961, Valid: 68.26%, Test: 81.87%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 104, Loss: 0.1961, Valid: 70.49%, Test: 91.08%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 105, Loss: 0.1956, Valid: 63.99%, Test: 33.15%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 105, Loss: 0.1956, Valid: 68.46%, Test: 76.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 105, Loss: 0.1956, Valid: 70.56%, Test: 91.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 106, Loss: 0.1964, Valid: 62.45%, Test: 30.81%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 106, Loss: 0.1964, Valid: 68.94%, Test: 83.43%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 106, Loss: 0.1964, Valid: 70.76%, Test: 90.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 107, Loss: 0.1953, Valid: 62.49%, Test: 53.79%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 107, Loss: 0.1953, Valid: 68.23%, Test: 84.11%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 107, Loss: 0.1953, Valid: 70.33%, Test: 92.09%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 108, Loss: 0.1947, Valid: 63.99%, Test: 51.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 108, Loss: 0.1947, Valid: 68.40%, Test: 83.95%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 108, Loss: 0.1947, Valid: 70.54%, Test: 92.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 109, Loss: 0.1940, Valid: 65.17%, Test: 22.49%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 109, Loss: 0.1940, Valid: 69.28%, Test: 77.13%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 109, Loss: 0.1940, Valid: 70.79%, Test: 91.90%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 110, Loss: 0.1942, Valid: 65.44%, Test: 27.19%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 110, Loss: 0.1942, Valid: 69.14%, Test: 77.80%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 110, Loss: 0.1942, Valid: 71.32%, Test: 92.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 111, Loss: 0.1936, Valid: 64.77%, Test: 44.17%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 111, Loss: 0.1936, Valid: 68.87%, Test: 85.70%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 111, Loss: 0.1936, Valid: 70.81%, Test: 92.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 112, Loss: 0.1936, Valid: 63.68%, Test: 40.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 112, Loss: 0.1936, Valid: 68.75%, Test: 80.79%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 112, Loss: 0.1936, Valid: 70.92%, Test: 90.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 113, Loss: 0.1933, Valid: 64.85%, Test: 62.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 113, Loss: 0.1933, Valid: 68.65%, Test: 87.49%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 113, Loss: 0.1933, Valid: 70.85%, Test: 91.99%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 114, Loss: 0.1946, Valid: 63.21%, Test: 44.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 114, Loss: 0.1946, Valid: 68.10%, Test: 81.33%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 114, Loss: 0.1946, Valid: 70.85%, Test: 91.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 115, Loss: 0.1914, Valid: 64.79%, Test: 50.65%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 115, Loss: 0.1914, Valid: 69.70%, Test: 85.75%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 115, Loss: 0.1914, Valid: 71.12%, Test: 92.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 116, Loss: 0.1912, Valid: 67.65%, Test: 59.74%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 116, Loss: 0.1912, Valid: 70.08%, Test: 86.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 116, Loss: 0.1912, Valid: 71.43%, Test: 93.01%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 117, Loss: 0.1915, Valid: 64.31%, Test: 62.21%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 117, Loss: 0.1915, Valid: 69.54%, Test: 86.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 117, Loss: 0.1915, Valid: 71.21%, Test: 92.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 118, Loss: 0.1910, Valid: 66.49%, Test: 46.11%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 118, Loss: 0.1910, Valid: 69.68%, Test: 87.13%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 118, Loss: 0.1910, Valid: 71.22%, Test: 92.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 119, Loss: 0.1915, Valid: 63.86%, Test: 47.05%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 119, Loss: 0.1915, Valid: 69.55%, Test: 82.54%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 119, Loss: 0.1915, Valid: 71.18%, Test: 92.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 120, Loss: 0.1889, Valid: 65.62%, Test: 53.14%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 120, Loss: 0.1889, Valid: 69.70%, Test: 88.53%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 120, Loss: 0.1889, Valid: 71.34%, Test: 93.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 121, Loss: 0.1897, Valid: 66.53%, Test: 30.47%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 121, Loss: 0.1897, Valid: 69.71%, Test: 87.82%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 121, Loss: 0.1897, Valid: 71.75%, Test: 93.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 122, Loss: 0.1900, Valid: 65.57%, Test: 47.22%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 122, Loss: 0.1900, Valid: 69.25%, Test: 86.80%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 122, Loss: 0.1900, Valid: 71.44%, Test: 93.29%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 123, Loss: 0.1896, Valid: 65.84%, Test: 34.10%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 123, Loss: 0.1896, Valid: 69.88%, Test: 86.81%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 123, Loss: 0.1896, Valid: 71.72%, Test: 93.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 124, Loss: 0.1901, Valid: 65.41%, Test: 52.57%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 124, Loss: 0.1901, Valid: 69.81%, Test: 86.16%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 124, Loss: 0.1901, Valid: 71.47%, Test: 93.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 125, Loss: 0.1898, Valid: 66.47%, Test: 66.31%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 125, Loss: 0.1898, Valid: 70.25%, Test: 89.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 125, Loss: 0.1898, Valid: 71.59%, Test: 93.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 126, Loss: 0.1888, Valid: 66.49%, Test: 59.09%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 126, Loss: 0.1888, Valid: 69.99%, Test: 85.40%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 126, Loss: 0.1888, Valid: 71.56%, Test: 93.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 127, Loss: 0.1886, Valid: 66.72%, Test: 68.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 127, Loss: 0.1886, Valid: 70.08%, Test: 90.43%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 127, Loss: 0.1886, Valid: 71.58%, Test: 93.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 128, Loss: 0.1884, Valid: 64.99%, Test: 68.52%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 128, Loss: 0.1884, Valid: 70.29%, Test: 86.52%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 128, Loss: 0.1884, Valid: 71.56%, Test: 93.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 129, Loss: 0.1870, Valid: 66.44%, Test: 62.76%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 129, Loss: 0.1870, Valid: 70.19%, Test: 88.07%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 129, Loss: 0.1870, Valid: 71.66%, Test: 93.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 130, Loss: 0.1882, Valid: 66.64%, Test: 37.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 130, Loss: 0.1882, Valid: 69.97%, Test: 85.43%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 130, Loss: 0.1882, Valid: 71.93%, Test: 93.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 131, Loss: 0.1869, Valid: 67.01%, Test: 62.55%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 131, Loss: 0.1869, Valid: 70.68%, Test: 89.43%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 131, Loss: 0.1869, Valid: 71.88%, Test: 93.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 132, Loss: 0.1863, Valid: 67.18%, Test: 59.23%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 132, Loss: 0.1863, Valid: 70.13%, Test: 88.48%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 132, Loss: 0.1863, Valid: 71.71%, Test: 94.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 133, Loss: 0.1860, Valid: 66.74%, Test: 52.52%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 133, Loss: 0.1860, Valid: 70.15%, Test: 89.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 133, Loss: 0.1860, Valid: 71.81%, Test: 93.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 134, Loss: 0.1857, Valid: 66.83%, Test: 52.06%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 134, Loss: 0.1857, Valid: 69.98%, Test: 87.28%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 134, Loss: 0.1857, Valid: 71.75%, Test: 94.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 135, Loss: 0.1875, Valid: 66.35%, Test: 48.23%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 135, Loss: 0.1875, Valid: 70.30%, Test: 89.67%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 135, Loss: 0.1875, Valid: 71.81%, Test: 94.43%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 136, Loss: 0.1855, Valid: 65.62%, Test: 41.98%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 136, Loss: 0.1855, Valid: 70.49%, Test: 87.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 136, Loss: 0.1855, Valid: 71.79%, Test: 93.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 137, Loss: 0.1848, Valid: 68.47%, Test: 65.13%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 137, Loss: 0.1848, Valid: 70.47%, Test: 88.06%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 137, Loss: 0.1848, Valid: 71.93%, Test: 94.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 138, Loss: 0.1842, Valid: 66.18%, Test: 46.01%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 138, Loss: 0.1842, Valid: 70.71%, Test: 85.26%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 138, Loss: 0.1842, Valid: 72.17%, Test: 94.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 139, Loss: 0.1852, Valid: 66.65%, Test: 55.66%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 139, Loss: 0.1852, Valid: 70.78%, Test: 88.20%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 139, Loss: 0.1852, Valid: 72.31%, Test: 94.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 140, Loss: 0.1842, Valid: 67.86%, Test: 37.75%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 140, Loss: 0.1842, Valid: 70.49%, Test: 81.29%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 140, Loss: 0.1842, Valid: 72.23%, Test: 94.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 141, Loss: 0.1853, Valid: 66.76%, Test: 34.78%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 141, Loss: 0.1853, Valid: 70.95%, Test: 86.24%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 141, Loss: 0.1853, Valid: 72.16%, Test: 94.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 142, Loss: 0.1828, Valid: 67.91%, Test: 45.61%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 142, Loss: 0.1828, Valid: 70.74%, Test: 89.82%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 142, Loss: 0.1828, Valid: 72.16%, Test: 94.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 143, Loss: 0.1844, Valid: 67.99%, Test: 41.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 143, Loss: 0.1844, Valid: 70.81%, Test: 88.23%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 143, Loss: 0.1844, Valid: 72.28%, Test: 94.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 144, Loss: 0.1836, Valid: 66.61%, Test: 46.82%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 144, Loss: 0.1836, Valid: 70.74%, Test: 87.69%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 144, Loss: 0.1836, Valid: 72.00%, Test: 94.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 145, Loss: 0.1846, Valid: 66.01%, Test: 30.92%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 145, Loss: 0.1846, Valid: 70.24%, Test: 86.86%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 145, Loss: 0.1846, Valid: 72.04%, Test: 94.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 146, Loss: 0.1844, Valid: 67.37%, Test: 46.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 146, Loss: 0.1844, Valid: 70.44%, Test: 88.29%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 146, Loss: 0.1844, Valid: 71.88%, Test: 94.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 147, Loss: 0.1833, Valid: 68.34%, Test: 25.42%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 147, Loss: 0.1833, Valid: 70.83%, Test: 81.49%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 147, Loss: 0.1833, Valid: 72.19%, Test: 94.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 148, Loss: 0.1820, Valid: 66.45%, Test: 59.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 148, Loss: 0.1820, Valid: 70.95%, Test: 89.32%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 148, Loss: 0.1820, Valid: 72.48%, Test: 94.62%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 149, Loss: 0.1822, Valid: 67.58%, Test: 51.96%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 149, Loss: 0.1822, Valid: 70.74%, Test: 89.05%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 149, Loss: 0.1822, Valid: 72.23%, Test: 95.34%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 150, Loss: 0.1830, Valid: 67.92%, Test: 54.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 150, Loss: 0.1830, Valid: 70.78%, Test: 87.56%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 150, Loss: 0.1830, Valid: 72.04%, Test: 93.99%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 151, Loss: 0.1830, Valid: 67.55%, Test: 51.42%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 151, Loss: 0.1830, Valid: 70.84%, Test: 88.49%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 151, Loss: 0.1830, Valid: 72.30%, Test: 95.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 152, Loss: 0.1824, Valid: 67.13%, Test: 47.24%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 152, Loss: 0.1824, Valid: 70.95%, Test: 91.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 152, Loss: 0.1824, Valid: 72.52%, Test: 95.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 153, Loss: 0.1824, Valid: 66.23%, Test: 56.90%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 153, Loss: 0.1824, Valid: 71.00%, Test: 88.76%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 153, Loss: 0.1824, Valid: 72.38%, Test: 95.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 154, Loss: 0.1815, Valid: 67.83%, Test: 46.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 154, Loss: 0.1815, Valid: 70.94%, Test: 89.52%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 154, Loss: 0.1815, Valid: 72.39%, Test: 95.28%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 155, Loss: 0.1827, Valid: 68.45%, Test: 39.73%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 155, Loss: 0.1827, Valid: 71.17%, Test: 85.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 155, Loss: 0.1827, Valid: 72.39%, Test: 94.93%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 156, Loss: 0.1811, Valid: 67.65%, Test: 51.98%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 156, Loss: 0.1811, Valid: 70.90%, Test: 89.19%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 156, Loss: 0.1811, Valid: 72.32%, Test: 95.28%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 157, Loss: 0.1808, Valid: 67.64%, Test: 62.35%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 157, Loss: 0.1808, Valid: 71.06%, Test: 89.56%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 157, Loss: 0.1808, Valid: 72.62%, Test: 95.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 158, Loss: 0.1817, Valid: 67.76%, Test: 56.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 158, Loss: 0.1817, Valid: 71.16%, Test: 91.33%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 158, Loss: 0.1817, Valid: 72.55%, Test: 95.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 159, Loss: 0.1808, Valid: 68.01%, Test: 51.21%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 159, Loss: 0.1808, Valid: 71.08%, Test: 90.40%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 159, Loss: 0.1808, Valid: 72.57%, Test: 95.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 160, Loss: 0.1818, Valid: 68.85%, Test: 59.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 160, Loss: 0.1818, Valid: 71.35%, Test: 90.56%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 160, Loss: 0.1818, Valid: 72.69%, Test: 95.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 161, Loss: 0.1794, Valid: 68.34%, Test: 58.10%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 161, Loss: 0.1794, Valid: 71.39%, Test: 91.86%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 161, Loss: 0.1794, Valid: 72.80%, Test: 95.88%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 162, Loss: 0.1786, Valid: 68.98%, Test: 29.53%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 162, Loss: 0.1786, Valid: 71.67%, Test: 90.93%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 162, Loss: 0.1786, Valid: 72.84%, Test: 95.68%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 163, Loss: 0.1787, Valid: 68.56%, Test: 54.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 163, Loss: 0.1787, Valid: 71.57%, Test: 91.96%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 163, Loss: 0.1787, Valid: 72.79%, Test: 95.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 164, Loss: 0.1807, Valid: 67.87%, Test: 33.80%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 164, Loss: 0.1807, Valid: 71.90%, Test: 88.52%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 164, Loss: 0.1807, Valid: 72.81%, Test: 95.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 165, Loss: 0.1797, Valid: 68.53%, Test: 43.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 165, Loss: 0.1797, Valid: 71.23%, Test: 89.32%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 165, Loss: 0.1797, Valid: 72.70%, Test: 94.98%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 166, Loss: 0.1785, Valid: 69.28%, Test: 65.39%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 166, Loss: 0.1785, Valid: 71.68%, Test: 91.38%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 166, Loss: 0.1785, Valid: 73.01%, Test: 95.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 167, Loss: 0.1782, Valid: 69.55%, Test: 53.81%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 167, Loss: 0.1782, Valid: 71.69%, Test: 88.80%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 167, Loss: 0.1782, Valid: 73.28%, Test: 95.91%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 168, Loss: 0.1784, Valid: 68.64%, Test: 44.24%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 168, Loss: 0.1784, Valid: 71.88%, Test: 89.01%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 168, Loss: 0.1784, Valid: 72.91%, Test: 95.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 169, Loss: 0.1795, Valid: 69.45%, Test: 60.18%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 169, Loss: 0.1795, Valid: 71.76%, Test: 88.27%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 169, Loss: 0.1795, Valid: 72.86%, Test: 95.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 170, Loss: 0.1808, Valid: 68.53%, Test: 31.10%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 170, Loss: 0.1808, Valid: 71.19%, Test: 88.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 170, Loss: 0.1808, Valid: 72.70%, Test: 95.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 171, Loss: 0.1795, Valid: 68.07%, Test: 49.62%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 171, Loss: 0.1795, Valid: 71.77%, Test: 85.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 171, Loss: 0.1795, Valid: 72.95%, Test: 95.26%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 172, Loss: 0.1787, Valid: 69.48%, Test: 40.84%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 172, Loss: 0.1787, Valid: 71.77%, Test: 87.40%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 172, Loss: 0.1787, Valid: 72.90%, Test: 96.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 173, Loss: 0.1791, Valid: 67.44%, Test: 56.71%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 173, Loss: 0.1791, Valid: 71.26%, Test: 89.95%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 173, Loss: 0.1791, Valid: 72.61%, Test: 95.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 174, Loss: 0.1783, Valid: 68.95%, Test: 46.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 174, Loss: 0.1783, Valid: 71.72%, Test: 89.93%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 174, Loss: 0.1783, Valid: 72.82%, Test: 96.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 175, Loss: 0.1776, Valid: 69.80%, Test: 66.11%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 175, Loss: 0.1776, Valid: 71.80%, Test: 91.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 175, Loss: 0.1776, Valid: 73.10%, Test: 95.94%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 176, Loss: 0.1773, Valid: 69.56%, Test: 64.54%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 176, Loss: 0.1773, Valid: 71.62%, Test: 90.32%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 176, Loss: 0.1773, Valid: 72.91%, Test: 96.07%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 177, Loss: 0.1775, Valid: 68.88%, Test: 51.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 177, Loss: 0.1775, Valid: 71.37%, Test: 88.02%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 177, Loss: 0.1775, Valid: 72.71%, Test: 95.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 178, Loss: 0.1769, Valid: 69.29%, Test: 51.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 178, Loss: 0.1769, Valid: 71.72%, Test: 87.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 178, Loss: 0.1769, Valid: 73.06%, Test: 95.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 179, Loss: 0.1777, Valid: 69.66%, Test: 57.42%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 179, Loss: 0.1777, Valid: 71.94%, Test: 89.00%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 179, Loss: 0.1777, Valid: 75.78%, Test: 96.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 180, Loss: 0.1780, Valid: 69.78%, Test: 74.96%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 180, Loss: 0.1780, Valid: 71.91%, Test: 90.62%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 180, Loss: 0.1780, Valid: 73.62%, Test: 96.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 181, Loss: 0.1764, Valid: 69.28%, Test: 62.71%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 181, Loss: 0.1764, Valid: 71.92%, Test: 91.26%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 181, Loss: 0.1764, Valid: 73.21%, Test: 96.28%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 182, Loss: 0.1772, Valid: 68.77%, Test: 69.02%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 182, Loss: 0.1772, Valid: 71.96%, Test: 90.69%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 182, Loss: 0.1772, Valid: 73.02%, Test: 95.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 183, Loss: 0.1760, Valid: 69.02%, Test: 66.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 183, Loss: 0.1760, Valid: 72.19%, Test: 93.40%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 183, Loss: 0.1760, Valid: 73.25%, Test: 96.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 184, Loss: 0.1764, Valid: 68.80%, Test: 70.89%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 184, Loss: 0.1764, Valid: 71.91%, Test: 92.59%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 184, Loss: 0.1764, Valid: 73.20%, Test: 96.19%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 185, Loss: 0.1755, Valid: 69.61%, Test: 57.30%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 185, Loss: 0.1755, Valid: 71.76%, Test: 92.78%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 185, Loss: 0.1755, Valid: 73.55%, Test: 96.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 186, Loss: 0.1757, Valid: 69.93%, Test: 56.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 186, Loss: 0.1757, Valid: 71.77%, Test: 89.49%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 186, Loss: 0.1757, Valid: 73.08%, Test: 95.94%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 187, Loss: 0.1768, Valid: 70.45%, Test: 65.64%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 187, Loss: 0.1768, Valid: 71.97%, Test: 91.07%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 187, Loss: 0.1768, Valid: 73.15%, Test: 96.33%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 188, Loss: 0.1760, Valid: 68.65%, Test: 72.16%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 188, Loss: 0.1760, Valid: 72.00%, Test: 91.61%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 188, Loss: 0.1760, Valid: 72.98%, Test: 96.55%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 189, Loss: 0.1770, Valid: 68.27%, Test: 68.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 189, Loss: 0.1770, Valid: 71.96%, Test: 91.74%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 189, Loss: 0.1770, Valid: 73.23%, Test: 96.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 190, Loss: 0.1753, Valid: 67.94%, Test: 47.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 190, Loss: 0.1753, Valid: 71.68%, Test: 86.72%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 190, Loss: 0.1753, Valid: 73.31%, Test: 95.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 191, Loss: 0.1765, Valid: 69.46%, Test: 54.17%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 191, Loss: 0.1765, Valid: 71.70%, Test: 89.35%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 191, Loss: 0.1765, Valid: 73.32%, Test: 96.07%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 192, Loss: 0.1767, Valid: 67.17%, Test: 65.67%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 192, Loss: 0.1767, Valid: 71.59%, Test: 90.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 192, Loss: 0.1767, Valid: 73.14%, Test: 96.12%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 193, Loss: 0.1755, Valid: 67.72%, Test: 61.13%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 193, Loss: 0.1755, Valid: 72.11%, Test: 91.95%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 193, Loss: 0.1755, Valid: 73.14%, Test: 96.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 194, Loss: 0.1767, Valid: 66.65%, Test: 71.01%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 194, Loss: 0.1767, Valid: 71.00%, Test: 88.84%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 194, Loss: 0.1767, Valid: 72.67%, Test: 95.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 195, Loss: 0.1758, Valid: 68.90%, Test: 55.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 195, Loss: 0.1758, Valid: 71.81%, Test: 90.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 195, Loss: 0.1758, Valid: 73.37%, Test: 96.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 196, Loss: 0.1751, Valid: 69.72%, Test: 75.94%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 196, Loss: 0.1751, Valid: 72.08%, Test: 93.16%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 196, Loss: 0.1751, Valid: 73.57%, Test: 96.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 197, Loss: 0.1757, Valid: 68.46%, Test: 52.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 197, Loss: 0.1757, Valid: 71.89%, Test: 90.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 197, Loss: 0.1757, Valid: 73.11%, Test: 96.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 198, Loss: 0.1736, Valid: 69.33%, Test: 67.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 198, Loss: 0.1736, Valid: 72.46%, Test: 92.94%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 198, Loss: 0.1736, Valid: 75.05%, Test: 96.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 199, Loss: 0.1757, Valid: 70.37%, Test: 78.69%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 199, Loss: 0.1757, Valid: 72.14%, Test: 93.21%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 199, Loss: 0.1757, Valid: 73.52%, Test: 96.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 200, Loss: 0.1749, Valid: 68.99%, Test: 75.67%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 200, Loss: 0.1749, Valid: 72.18%, Test: 92.89%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 200, Loss: 0.1749, Valid: 73.61%, Test: 96.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 201, Loss: 0.1748, Valid: 70.29%, Test: 54.71%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 201, Loss: 0.1748, Valid: 72.20%, Test: 92.65%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 201, Loss: 0.1748, Valid: 73.36%, Test: 96.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 202, Loss: 0.1742, Valid: 63.76%, Test: 58.22%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 202, Loss: 0.1742, Valid: 71.99%, Test: 86.15%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 202, Loss: 0.1742, Valid: 73.19%, Test: 95.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 203, Loss: 0.1743, Valid: 68.33%, Test: 67.97%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 203, Loss: 0.1743, Valid: 71.90%, Test: 90.82%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 203, Loss: 0.1743, Valid: 73.17%, Test: 96.40%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 204, Loss: 0.1751, Valid: 68.80%, Test: 71.66%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 204, Loss: 0.1751, Valid: 72.52%, Test: 94.04%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 204, Loss: 0.1751, Valid: 78.68%, Test: 96.93%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 205, Loss: 0.1741, Valid: 70.41%, Test: 78.70%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 205, Loss: 0.1741, Valid: 72.49%, Test: 93.15%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 205, Loss: 0.1741, Valid: 74.07%, Test: 96.90%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 206, Loss: 0.1747, Valid: 69.56%, Test: 79.01%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 206, Loss: 0.1747, Valid: 72.32%, Test: 93.59%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 206, Loss: 0.1747, Valid: 74.18%, Test: 97.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 207, Loss: 0.1749, Valid: 68.98%, Test: 73.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 207, Loss: 0.1749, Valid: 72.41%, Test: 93.41%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 207, Loss: 0.1749, Valid: 78.81%, Test: 97.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 208, Loss: 0.1740, Valid: 68.29%, Test: 81.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 208, Loss: 0.1740, Valid: 71.93%, Test: 93.23%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 208, Loss: 0.1740, Valid: 74.07%, Test: 96.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 209, Loss: 0.1737, Valid: 68.65%, Test: 68.73%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 209, Loss: 0.1737, Valid: 71.95%, Test: 92.20%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 209, Loss: 0.1737, Valid: 73.18%, Test: 96.66%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 210, Loss: 0.1740, Valid: 68.85%, Test: 68.76%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 210, Loss: 0.1740, Valid: 72.64%, Test: 92.80%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 210, Loss: 0.1740, Valid: 74.63%, Test: 96.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 211, Loss: 0.1735, Valid: 70.14%, Test: 73.62%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 211, Loss: 0.1735, Valid: 72.58%, Test: 92.84%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 211, Loss: 0.1735, Valid: 78.11%, Test: 96.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 212, Loss: 0.1731, Valid: 69.65%, Test: 58.01%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 212, Loss: 0.1731, Valid: 72.40%, Test: 93.54%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 212, Loss: 0.1731, Valid: 73.68%, Test: 97.06%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 213, Loss: 0.1739, Valid: 69.44%, Test: 56.86%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 213, Loss: 0.1739, Valid: 72.35%, Test: 89.72%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 213, Loss: 0.1739, Valid: 73.44%, Test: 95.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 214, Loss: 0.1743, Valid: 67.62%, Test: 64.35%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 214, Loss: 0.1743, Valid: 72.22%, Test: 92.65%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 214, Loss: 0.1743, Valid: 73.42%, Test: 97.16%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 215, Loss: 0.1746, Valid: 70.12%, Test: 62.68%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 215, Loss: 0.1746, Valid: 72.70%, Test: 93.16%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 215, Loss: 0.1746, Valid: 73.59%, Test: 97.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 216, Loss: 0.1733, Valid: 68.28%, Test: 79.58%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 216, Loss: 0.1733, Valid: 72.26%, Test: 92.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 216, Loss: 0.1733, Valid: 73.91%, Test: 96.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 217, Loss: 0.1745, Valid: 69.83%, Test: 64.64%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 217, Loss: 0.1745, Valid: 72.54%, Test: 92.72%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 217, Loss: 0.1745, Valid: 73.92%, Test: 97.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 218, Loss: 0.1738, Valid: 69.43%, Test: 60.47%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 218, Loss: 0.1738, Valid: 72.55%, Test: 91.83%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 218, Loss: 0.1738, Valid: 75.60%, Test: 96.80%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 219, Loss: 0.1743, Valid: 67.89%, Test: 66.76%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 219, Loss: 0.1743, Valid: 72.69%, Test: 91.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 219, Loss: 0.1743, Valid: 76.82%, Test: 96.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 220, Loss: 0.1732, Valid: 69.58%, Test: 77.40%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 220, Loss: 0.1732, Valid: 72.72%, Test: 94.21%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 220, Loss: 0.1732, Valid: 74.50%, Test: 97.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 221, Loss: 0.1712, Valid: 69.29%, Test: 81.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 221, Loss: 0.1712, Valid: 72.83%, Test: 93.74%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 221, Loss: 0.1712, Valid: 81.35%, Test: 97.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 222, Loss: 0.1723, Valid: 69.51%, Test: 56.36%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 222, Loss: 0.1723, Valid: 72.06%, Test: 88.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 222, Loss: 0.1723, Valid: 73.50%, Test: 96.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 223, Loss: 0.1729, Valid: 70.54%, Test: 55.89%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 223, Loss: 0.1729, Valid: 72.75%, Test: 93.76%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 223, Loss: 0.1729, Valid: 74.41%, Test: 97.17%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 224, Loss: 0.1718, Valid: 70.58%, Test: 81.30%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 224, Loss: 0.1718, Valid: 72.50%, Test: 94.83%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 224, Loss: 0.1718, Valid: 74.44%, Test: 97.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 225, Loss: 0.1730, Valid: 69.99%, Test: 74.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 225, Loss: 0.1730, Valid: 72.29%, Test: 93.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 225, Loss: 0.1730, Valid: 73.50%, Test: 97.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 226, Loss: 0.1732, Valid: 70.01%, Test: 76.91%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 226, Loss: 0.1732, Valid: 72.58%, Test: 94.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 226, Loss: 0.1732, Valid: 73.56%, Test: 97.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 227, Loss: 0.1732, Valid: 65.83%, Test: 80.07%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 227, Loss: 0.1732, Valid: 72.01%, Test: 93.77%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 227, Loss: 0.1732, Valid: 73.51%, Test: 97.23%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 228, Loss: 0.1729, Valid: 68.72%, Test: 74.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 228, Loss: 0.1729, Valid: 72.18%, Test: 94.61%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 228, Loss: 0.1729, Valid: 74.25%, Test: 97.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 229, Loss: 0.1730, Valid: 69.14%, Test: 84.71%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 229, Loss: 0.1730, Valid: 72.59%, Test: 95.26%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 229, Loss: 0.1730, Valid: 80.57%, Test: 97.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 230, Loss: 0.1725, Valid: 69.41%, Test: 52.09%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 230, Loss: 0.1725, Valid: 72.58%, Test: 90.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 230, Loss: 0.1725, Valid: 73.44%, Test: 96.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 231, Loss: 0.1725, Valid: 69.63%, Test: 72.76%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 231, Loss: 0.1725, Valid: 72.66%, Test: 93.78%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 231, Loss: 0.1725, Valid: 73.70%, Test: 96.98%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 232, Loss: 0.1735, Valid: 69.77%, Test: 82.47%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 232, Loss: 0.1735, Valid: 72.73%, Test: 95.15%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 232, Loss: 0.1735, Valid: 95.24%, Test: 97.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 233, Loss: 0.1722, Valid: 69.14%, Test: 68.91%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 233, Loss: 0.1722, Valid: 72.64%, Test: 93.46%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 233, Loss: 0.1722, Valid: 74.27%, Test: 97.13%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 234, Loss: 0.1714, Valid: 69.43%, Test: 83.18%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 234, Loss: 0.1714, Valid: 72.60%, Test: 94.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 234, Loss: 0.1714, Valid: 78.03%, Test: 97.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 235, Loss: 0.1712, Valid: 68.80%, Test: 82.28%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 235, Loss: 0.1712, Valid: 72.57%, Test: 94.72%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 235, Loss: 0.1712, Valid: 83.60%, Test: 97.49%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 236, Loss: 0.1712, Valid: 69.61%, Test: 67.00%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 236, Loss: 0.1712, Valid: 72.69%, Test: 92.77%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 236, Loss: 0.1712, Valid: 73.73%, Test: 97.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 237, Loss: 0.1725, Valid: 69.42%, Test: 84.92%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 237, Loss: 0.1725, Valid: 72.83%, Test: 95.18%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 237, Loss: 0.1725, Valid: 79.56%, Test: 97.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 238, Loss: 0.1723, Valid: 69.54%, Test: 83.07%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 238, Loss: 0.1723, Valid: 72.91%, Test: 95.77%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 238, Loss: 0.1723, Valid: 94.13%, Test: 97.81%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 239, Loss: 0.1703, Valid: 69.45%, Test: 76.85%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 239, Loss: 0.1703, Valid: 72.43%, Test: 93.98%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 239, Loss: 0.1703, Valid: 75.90%, Test: 97.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 240, Loss: 0.1712, Valid: 69.99%, Test: 64.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 240, Loss: 0.1712, Valid: 72.63%, Test: 94.46%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 240, Loss: 0.1712, Valid: 74.56%, Test: 97.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 241, Loss: 0.1713, Valid: 70.03%, Test: 71.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 241, Loss: 0.1713, Valid: 72.65%, Test: 93.79%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 241, Loss: 0.1713, Valid: 78.40%, Test: 97.49%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 242, Loss: 0.1704, Valid: 69.68%, Test: 75.78%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 242, Loss: 0.1704, Valid: 72.81%, Test: 94.01%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 242, Loss: 0.1704, Valid: 83.43%, Test: 97.78%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 243, Loss: 0.1709, Valid: 67.32%, Test: 74.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 243, Loss: 0.1709, Valid: 72.61%, Test: 93.19%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 243, Loss: 0.1709, Valid: 80.80%, Test: 97.74%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 244, Loss: 0.1716, Valid: 70.71%, Test: 80.72%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 244, Loss: 0.1716, Valid: 72.57%, Test: 95.57%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 244, Loss: 0.1716, Valid: 82.91%, Test: 97.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 245, Loss: 0.1702, Valid: 68.34%, Test: 77.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 245, Loss: 0.1702, Valid: 72.67%, Test: 93.21%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 245, Loss: 0.1702, Valid: 81.97%, Test: 97.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 246, Loss: 0.1737, Valid: 69.85%, Test: 78.70%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 246, Loss: 0.1737, Valid: 72.36%, Test: 94.50%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 246, Loss: 0.1737, Valid: 73.44%, Test: 97.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 247, Loss: 0.1717, Valid: 68.20%, Test: 73.45%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 247, Loss: 0.1717, Valid: 72.51%, Test: 94.89%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 247, Loss: 0.1717, Valid: 73.90%, Test: 97.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 248, Loss: 0.1708, Valid: 69.58%, Test: 85.80%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 248, Loss: 0.1708, Valid: 72.87%, Test: 94.79%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 248, Loss: 0.1708, Valid: 77.69%, Test: 97.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 249, Loss: 0.1709, Valid: 70.68%, Test: 76.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 249, Loss: 0.1709, Valid: 72.92%, Test: 94.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 249, Loss: 0.1709, Valid: 79.45%, Test: 97.69%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 250, Loss: 0.1705, Valid: 68.22%, Test: 80.74%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 250, Loss: 0.1705, Valid: 72.64%, Test: 94.40%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 250, Loss: 0.1705, Valid: 83.88%, Test: 97.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 251, Loss: 0.1700, Valid: 70.91%, Test: 76.27%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 251, Loss: 0.1700, Valid: 73.00%, Test: 94.38%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 251, Loss: 0.1700, Valid: 82.84%, Test: 97.83%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 252, Loss: 0.1710, Valid: 70.00%, Test: 82.28%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 252, Loss: 0.1710, Valid: 73.07%, Test: 95.67%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 252, Loss: 0.1710, Valid: 92.59%, Test: 97.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 253, Loss: 0.1691, Valid: 71.23%, Test: 73.36%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 253, Loss: 0.1691, Valid: 73.06%, Test: 96.38%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 253, Loss: 0.1691, Valid: 90.44%, Test: 98.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 254, Loss: 0.1693, Valid: 70.30%, Test: 72.12%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 254, Loss: 0.1693, Valid: 72.86%, Test: 94.37%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 254, Loss: 0.1693, Valid: 74.46%, Test: 97.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 255, Loss: 0.1696, Valid: 69.55%, Test: 74.84%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 255, Loss: 0.1696, Valid: 72.58%, Test: 94.02%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 255, Loss: 0.1696, Valid: 79.10%, Test: 97.83%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 256, Loss: 0.1696, Valid: 69.20%, Test: 72.18%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 256, Loss: 0.1696, Valid: 72.66%, Test: 93.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 256, Loss: 0.1696, Valid: 75.24%, Test: 97.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 257, Loss: 0.1699, Valid: 70.23%, Test: 84.09%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 257, Loss: 0.1699, Valid: 72.90%, Test: 94.21%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 257, Loss: 0.1699, Valid: 89.31%, Test: 97.92%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 258, Loss: 0.1696, Valid: 70.41%, Test: 88.52%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 258, Loss: 0.1696, Valid: 73.14%, Test: 95.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 258, Loss: 0.1696, Valid: 96.44%, Test: 97.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 259, Loss: 0.1701, Valid: 71.04%, Test: 86.52%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 259, Loss: 0.1701, Valid: 73.28%, Test: 94.96%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 259, Loss: 0.1701, Valid: 97.35%, Test: 97.86%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 260, Loss: 0.1703, Valid: 68.85%, Test: 79.79%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 260, Loss: 0.1703, Valid: 72.83%, Test: 95.21%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 260, Loss: 0.1703, Valid: 88.10%, Test: 97.84%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 261, Loss: 0.1690, Valid: 69.78%, Test: 77.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 261, Loss: 0.1690, Valid: 73.02%, Test: 94.62%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 261, Loss: 0.1690, Valid: 91.69%, Test: 97.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 262, Loss: 0.1706, Valid: 70.12%, Test: 87.79%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 262, Loss: 0.1706, Valid: 73.11%, Test: 95.61%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 262, Loss: 0.1706, Valid: 89.98%, Test: 97.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 263, Loss: 0.1691, Valid: 71.05%, Test: 79.96%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 263, Loss: 0.1691, Valid: 73.16%, Test: 94.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 263, Loss: 0.1691, Valid: 82.19%, Test: 97.92%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 264, Loss: 0.1695, Valid: 70.74%, Test: 79.44%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 264, Loss: 0.1695, Valid: 72.92%, Test: 94.48%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 264, Loss: 0.1695, Valid: 87.16%, Test: 98.11%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 265, Loss: 0.1696, Valid: 70.09%, Test: 78.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 265, Loss: 0.1696, Valid: 73.20%, Test: 95.52%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 265, Loss: 0.1696, Valid: 82.54%, Test: 98.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 266, Loss: 0.1690, Valid: 69.65%, Test: 77.83%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 266, Loss: 0.1690, Valid: 73.00%, Test: 94.62%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 266, Loss: 0.1690, Valid: 95.59%, Test: 97.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 267, Loss: 0.1686, Valid: 70.08%, Test: 82.14%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 267, Loss: 0.1686, Valid: 73.36%, Test: 95.45%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 267, Loss: 0.1686, Valid: 94.38%, Test: 98.03%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 268, Loss: 0.1685, Valid: 69.97%, Test: 62.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 268, Loss: 0.1685, Valid: 73.09%, Test: 95.02%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 268, Loss: 0.1685, Valid: 91.11%, Test: 97.97%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 269, Loss: 0.1700, Valid: 70.10%, Test: 85.60%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 269, Loss: 0.1700, Valid: 72.94%, Test: 95.96%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 269, Loss: 0.1700, Valid: 95.33%, Test: 98.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 270, Loss: 0.1692, Valid: 68.35%, Test: 78.69%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 270, Loss: 0.1692, Valid: 72.81%, Test: 95.52%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 270, Loss: 0.1692, Valid: 75.09%, Test: 97.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 271, Loss: 0.1695, Valid: 69.08%, Test: 80.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 271, Loss: 0.1695, Valid: 73.12%, Test: 95.97%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 271, Loss: 0.1695, Valid: 91.72%, Test: 97.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 272, Loss: 0.1698, Valid: 70.44%, Test: 85.94%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 272, Loss: 0.1698, Valid: 73.20%, Test: 94.93%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 272, Loss: 0.1698, Valid: 82.23%, Test: 98.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 273, Loss: 0.1680, Valid: 70.13%, Test: 73.28%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 273, Loss: 0.1680, Valid: 72.97%, Test: 92.29%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 273, Loss: 0.1680, Valid: 74.11%, Test: 97.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 274, Loss: 0.1696, Valid: 71.03%, Test: 83.03%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 274, Loss: 0.1696, Valid: 73.52%, Test: 96.00%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 274, Loss: 0.1696, Valid: 97.22%, Test: 98.05%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 275, Loss: 0.1677, Valid: 70.41%, Test: 74.95%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 275, Loss: 0.1677, Valid: 72.97%, Test: 93.93%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 275, Loss: 0.1677, Valid: 88.43%, Test: 98.02%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 276, Loss: 0.1689, Valid: 70.78%, Test: 85.83%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 276, Loss: 0.1689, Valid: 73.55%, Test: 95.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 276, Loss: 0.1689, Valid: 96.89%, Test: 97.85%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 277, Loss: 0.1700, Valid: 70.23%, Test: 80.48%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 277, Loss: 0.1700, Valid: 72.98%, Test: 95.36%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 277, Loss: 0.1700, Valid: 94.48%, Test: 97.95%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 278, Loss: 0.1684, Valid: 70.30%, Test: 82.75%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 278, Loss: 0.1684, Valid: 72.97%, Test: 95.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 278, Loss: 0.1684, Valid: 85.09%, Test: 97.98%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 279, Loss: 0.1685, Valid: 69.47%, Test: 60.96%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 279, Loss: 0.1685, Valid: 72.87%, Test: 94.72%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 279, Loss: 0.1685, Valid: 75.12%, Test: 97.87%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 280, Loss: 0.1696, Valid: 70.18%, Test: 82.54%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 280, Loss: 0.1696, Valid: 73.12%, Test: 95.11%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 280, Loss: 0.1696, Valid: 96.55%, Test: 97.90%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 281, Loss: 0.1686, Valid: 71.32%, Test: 83.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 281, Loss: 0.1686, Valid: 74.04%, Test: 95.31%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 281, Loss: 0.1686, Valid: 97.19%, Test: 98.10%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 282, Loss: 0.1689, Valid: 69.50%, Test: 69.53%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 282, Loss: 0.1689, Valid: 72.84%, Test: 93.15%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 282, Loss: 0.1689, Valid: 78.47%, Test: 97.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 283, Loss: 0.1688, Valid: 68.23%, Test: 79.06%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 283, Loss: 0.1688, Valid: 72.87%, Test: 92.98%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 283, Loss: 0.1688, Valid: 83.37%, Test: 97.96%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 284, Loss: 0.1684, Valid: 70.44%, Test: 79.56%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 284, Loss: 0.1684, Valid: 73.15%, Test: 95.93%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 284, Loss: 0.1684, Valid: 95.95%, Test: 98.22%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 285, Loss: 0.1673, Valid: 70.95%, Test: 90.48%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 285, Loss: 0.1673, Valid: 73.35%, Test: 96.27%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 285, Loss: 0.1673, Valid: 93.22%, Test: 98.37%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 286, Loss: 0.1685, Valid: 71.11%, Test: 85.40%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 286, Loss: 0.1685, Valid: 73.61%, Test: 95.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 286, Loss: 0.1685, Valid: 94.65%, Test: 98.25%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 287, Loss: 0.1672, Valid: 70.90%, Test: 82.22%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 287, Loss: 0.1672, Valid: 73.16%, Test: 95.81%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 287, Loss: 0.1672, Valid: 95.51%, Test: 97.89%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 288, Loss: 0.1683, Valid: 70.15%, Test: 85.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 288, Loss: 0.1683, Valid: 73.32%, Test: 94.77%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 288, Loss: 0.1683, Valid: 95.20%, Test: 97.91%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 289, Loss: 0.1685, Valid: 70.93%, Test: 72.30%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 289, Loss: 0.1685, Valid: 73.17%, Test: 92.10%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 289, Loss: 0.1685, Valid: 84.98%, Test: 97.75%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 290, Loss: 0.1685, Valid: 68.78%, Test: 77.26%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 290, Loss: 0.1685, Valid: 73.09%, Test: 93.78%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 290, Loss: 0.1685, Valid: 80.86%, Test: 97.79%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 291, Loss: 0.1684, Valid: 71.09%, Test: 85.16%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 291, Loss: 0.1684, Valid: 73.52%, Test: 96.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 291, Loss: 0.1684, Valid: 96.97%, Test: 98.13%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 292, Loss: 0.1688, Valid: 69.83%, Test: 74.91%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 292, Loss: 0.1688, Valid: 72.97%, Test: 94.61%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 292, Loss: 0.1688, Valid: 78.29%, Test: 97.92%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 293, Loss: 0.1682, Valid: 70.62%, Test: 87.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 293, Loss: 0.1682, Valid: 73.30%, Test: 95.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 293, Loss: 0.1682, Valid: 96.62%, Test: 98.14%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 294, Loss: 0.1686, Valid: 71.07%, Test: 78.08%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 294, Loss: 0.1686, Valid: 73.04%, Test: 93.99%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 294, Loss: 0.1686, Valid: 82.91%, Test: 98.15%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 295, Loss: 0.1679, Valid: 70.59%, Test: 85.17%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 295, Loss: 0.1679, Valid: 73.28%, Test: 96.42%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 295, Loss: 0.1679, Valid: 83.60%, Test: 98.43%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 296, Loss: 0.1675, Valid: 70.29%, Test: 83.77%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 296, Loss: 0.1675, Valid: 73.10%, Test: 96.01%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 296, Loss: 0.1675, Valid: 85.95%, Test: 98.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 297, Loss: 0.1676, Valid: 70.59%, Test: 75.99%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 297, Loss: 0.1676, Valid: 73.15%, Test: 94.96%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 297, Loss: 0.1676, Valid: 85.48%, Test: 98.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 298, Loss: 0.1677, Valid: 69.82%, Test: 74.14%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 298, Loss: 0.1677, Valid: 72.82%, Test: 94.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 298, Loss: 0.1677, Valid: 84.41%, Test: 98.06%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 299, Loss: 0.1678, Valid: 68.66%, Test: 80.45%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 299, Loss: 0.1678, Valid: 72.61%, Test: 94.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 299, Loss: 0.1678, Valid: 76.13%, Test: 97.82%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 300, Loss: 0.1689, Valid: 69.98%, Test: 82.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 300, Loss: 0.1689, Valid: 73.12%, Test: 95.53%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 300, Loss: 0.1689, Valid: 87.71%, Test: 98.19%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 301, Loss: 0.1681, Valid: 70.49%, Test: 86.75%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 301, Loss: 0.1681, Valid: 74.06%, Test: 95.84%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 301, Loss: 0.1681, Valid: 97.04%, Test: 97.91%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 302, Loss: 0.1679, Valid: 70.69%, Test: 86.73%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 302, Loss: 0.1679, Valid: 73.46%, Test: 96.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 302, Loss: 0.1679, Valid: 97.32%, Test: 98.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 303, Loss: 0.1676, Valid: 66.41%, Test: 73.39%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 303, Loss: 0.1676, Valid: 72.72%, Test: 94.59%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 303, Loss: 0.1676, Valid: 78.03%, Test: 98.09%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 304, Loss: 0.1669, Valid: 70.03%, Test: 87.08%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 304, Loss: 0.1669, Valid: 73.22%, Test: 94.94%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 304, Loss: 0.1669, Valid: 93.08%, Test: 98.13%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 305, Loss: 0.1661, Valid: 70.60%, Test: 84.93%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 305, Loss: 0.1661, Valid: 73.40%, Test: 96.81%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 305, Loss: 0.1661, Valid: 96.52%, Test: 98.24%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 306, Loss: 0.1676, Valid: 68.90%, Test: 86.02%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 306, Loss: 0.1676, Valid: 73.24%, Test: 96.41%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 306, Loss: 0.1676, Valid: 93.07%, Test: 98.07%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 307, Loss: 0.1680, Valid: 70.66%, Test: 81.70%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 307, Loss: 0.1680, Valid: 73.25%, Test: 95.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 307, Loss: 0.1680, Valid: 97.30%, Test: 98.22%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 308, Loss: 0.1680, Valid: 70.37%, Test: 60.13%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 308, Loss: 0.1680, Valid: 73.13%, Test: 93.70%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 308, Loss: 0.1680, Valid: 88.91%, Test: 98.00%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 309, Loss: 0.1682, Valid: 70.08%, Test: 83.74%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 309, Loss: 0.1682, Valid: 73.10%, Test: 96.05%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 309, Loss: 0.1682, Valid: 96.72%, Test: 98.05%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 310, Loss: 0.1666, Valid: 67.82%, Test: 72.28%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 310, Loss: 0.1666, Valid: 72.18%, Test: 91.36%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 310, Loss: 0.1666, Valid: 73.72%, Test: 97.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 311, Loss: 0.1668, Valid: 69.18%, Test: 84.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 311, Loss: 0.1668, Valid: 73.41%, Test: 96.57%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 311, Loss: 0.1668, Valid: 96.85%, Test: 98.31%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 312, Loss: 0.1668, Valid: 70.45%, Test: 84.75%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 312, Loss: 0.1668, Valid: 73.23%, Test: 95.78%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 312, Loss: 0.1668, Valid: 91.35%, Test: 98.31%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 313, Loss: 0.1663, Valid: 68.88%, Test: 84.93%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 313, Loss: 0.1663, Valid: 72.96%, Test: 95.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 313, Loss: 0.1663, Valid: 86.83%, Test: 97.98%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 314, Loss: 0.1664, Valid: 71.52%, Test: 86.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 314, Loss: 0.1664, Valid: 73.43%, Test: 96.78%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 314, Loss: 0.1664, Valid: 97.06%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 315, Loss: 0.1671, Valid: 69.58%, Test: 78.86%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 315, Loss: 0.1671, Valid: 73.30%, Test: 96.03%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 315, Loss: 0.1671, Valid: 92.50%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 316, Loss: 0.1673, Valid: 70.86%, Test: 75.03%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 316, Loss: 0.1673, Valid: 73.24%, Test: 92.75%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 316, Loss: 0.1673, Valid: 88.34%, Test: 97.99%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 317, Loss: 0.1663, Valid: 69.36%, Test: 81.87%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 317, Loss: 0.1663, Valid: 73.23%, Test: 95.42%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 317, Loss: 0.1663, Valid: 94.43%, Test: 98.27%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 318, Loss: 0.1666, Valid: 70.26%, Test: 86.07%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 318, Loss: 0.1666, Valid: 73.47%, Test: 96.64%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 318, Loss: 0.1666, Valid: 97.43%, Test: 98.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 319, Loss: 0.1668, Valid: 69.90%, Test: 80.14%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 319, Loss: 0.1668, Valid: 73.49%, Test: 95.92%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 319, Loss: 0.1668, Valid: 97.33%, Test: 98.18%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 320, Loss: 0.1673, Valid: 68.29%, Test: 74.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 320, Loss: 0.1673, Valid: 73.07%, Test: 93.39%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 320, Loss: 0.1673, Valid: 92.77%, Test: 98.21%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 321, Loss: 0.1668, Valid: 70.77%, Test: 84.75%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 321, Loss: 0.1668, Valid: 72.92%, Test: 96.25%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 321, Loss: 0.1668, Valid: 94.67%, Test: 98.29%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 322, Loss: 0.1666, Valid: 70.71%, Test: 89.21%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 322, Loss: 0.1666, Valid: 73.39%, Test: 96.54%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 322, Loss: 0.1666, Valid: 95.94%, Test: 98.49%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 323, Loss: 0.1674, Valid: 69.75%, Test: 86.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 323, Loss: 0.1674, Valid: 72.96%, Test: 96.28%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 323, Loss: 0.1674, Valid: 95.04%, Test: 98.41%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 324, Loss: 0.1666, Valid: 68.28%, Test: 79.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 324, Loss: 0.1666, Valid: 73.50%, Test: 96.17%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 324, Loss: 0.1666, Valid: 97.92%, Test: 98.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 325, Loss: 0.1668, Valid: 70.86%, Test: 76.85%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 325, Loss: 0.1668, Valid: 73.48%, Test: 96.92%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 325, Loss: 0.1668, Valid: 97.80%, Test: 98.46%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 326, Loss: 0.1675, Valid: 68.83%, Test: 80.79%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 326, Loss: 0.1675, Valid: 72.84%, Test: 96.25%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 326, Loss: 0.1675, Valid: 93.61%, Test: 98.36%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 327, Loss: 0.1672, Valid: 70.38%, Test: 79.46%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 327, Loss: 0.1672, Valid: 73.12%, Test: 95.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 327, Loss: 0.1672, Valid: 89.07%, Test: 98.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 328, Loss: 0.1660, Valid: 67.30%, Test: 86.20%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 328, Loss: 0.1660, Valid: 73.15%, Test: 95.94%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 328, Loss: 0.1660, Valid: 96.60%, Test: 98.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 329, Loss: 0.1668, Valid: 69.41%, Test: 82.71%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 329, Loss: 0.1668, Valid: 73.19%, Test: 96.07%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 329, Loss: 0.1668, Valid: 94.52%, Test: 98.20%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 330, Loss: 0.1660, Valid: 68.96%, Test: 84.32%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 330, Loss: 0.1660, Valid: 73.31%, Test: 96.54%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 330, Loss: 0.1660, Valid: 95.98%, Test: 98.36%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 331, Loss: 0.1652, Valid: 68.51%, Test: 81.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 331, Loss: 0.1652, Valid: 72.72%, Test: 95.14%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 331, Loss: 0.1652, Valid: 80.39%, Test: 98.09%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 332, Loss: 0.1667, Valid: 69.11%, Test: 81.92%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 332, Loss: 0.1667, Valid: 72.89%, Test: 94.89%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 332, Loss: 0.1667, Valid: 94.28%, Test: 98.06%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 333, Loss: 0.1669, Valid: 69.93%, Test: 75.48%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 333, Loss: 0.1669, Valid: 72.83%, Test: 92.99%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 333, Loss: 0.1669, Valid: 83.13%, Test: 98.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 334, Loss: 0.1670, Valid: 70.29%, Test: 82.31%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 334, Loss: 0.1670, Valid: 73.12%, Test: 95.03%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 334, Loss: 0.1670, Valid: 90.78%, Test: 98.42%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 335, Loss: 0.1665, Valid: 69.85%, Test: 83.23%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 335, Loss: 0.1665, Valid: 73.28%, Test: 96.58%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 335, Loss: 0.1665, Valid: 96.71%, Test: 98.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 336, Loss: 0.1678, Valid: 69.39%, Test: 80.48%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 336, Loss: 0.1678, Valid: 73.32%, Test: 94.96%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 336, Loss: 0.1678, Valid: 95.01%, Test: 98.39%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 337, Loss: 0.1669, Valid: 69.94%, Test: 82.12%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 337, Loss: 0.1669, Valid: 73.71%, Test: 95.75%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 337, Loss: 0.1669, Valid: 97.61%, Test: 98.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 338, Loss: 0.1673, Valid: 69.72%, Test: 88.16%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 338, Loss: 0.1673, Valid: 74.26%, Test: 96.60%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 338, Loss: 0.1673, Valid: 98.03%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 339, Loss: 0.1656, Valid: 70.09%, Test: 79.81%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 339, Loss: 0.1656, Valid: 73.34%, Test: 95.07%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 339, Loss: 0.1656, Valid: 97.54%, Test: 98.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 340, Loss: 0.1658, Valid: 69.95%, Test: 82.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 340, Loss: 0.1658, Valid: 73.34%, Test: 95.63%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 340, Loss: 0.1658, Valid: 92.77%, Test: 98.38%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 341, Loss: 0.1653, Valid: 69.64%, Test: 72.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 341, Loss: 0.1653, Valid: 73.42%, Test: 95.29%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 341, Loss: 0.1653, Valid: 95.51%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 342, Loss: 0.1649, Valid: 70.50%, Test: 83.56%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 342, Loss: 0.1649, Valid: 73.24%, Test: 95.83%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 342, Loss: 0.1649, Valid: 94.81%, Test: 98.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 343, Loss: 0.1665, Valid: 71.42%, Test: 75.51%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 343, Loss: 0.1665, Valid: 73.37%, Test: 96.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 343, Loss: 0.1665, Valid: 95.17%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 344, Loss: 0.1665, Valid: 70.95%, Test: 83.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 344, Loss: 0.1665, Valid: 73.43%, Test: 96.38%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 344, Loss: 0.1665, Valid: 94.21%, Test: 98.76%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 345, Loss: 0.1650, Valid: 70.95%, Test: 86.89%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 345, Loss: 0.1650, Valid: 73.22%, Test: 96.71%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 345, Loss: 0.1650, Valid: 97.50%, Test: 98.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 346, Loss: 0.1645, Valid: 70.42%, Test: 81.08%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 346, Loss: 0.1645, Valid: 73.33%, Test: 95.11%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 346, Loss: 0.1645, Valid: 92.29%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 347, Loss: 0.1662, Valid: 68.00%, Test: 75.90%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 347, Loss: 0.1662, Valid: 73.77%, Test: 95.43%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 347, Loss: 0.1662, Valid: 97.17%, Test: 98.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 348, Loss: 0.1659, Valid: 70.27%, Test: 76.59%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 348, Loss: 0.1659, Valid: 73.46%, Test: 95.08%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 348, Loss: 0.1659, Valid: 95.58%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 349, Loss: 0.1656, Valid: 70.38%, Test: 87.39%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 349, Loss: 0.1656, Valid: 83.03%, Test: 97.14%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 349, Loss: 0.1656, Valid: 98.47%, Test: 98.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 350, Loss: 0.1658, Valid: 69.27%, Test: 85.83%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 350, Loss: 0.1658, Valid: 73.39%, Test: 97.04%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 350, Loss: 0.1658, Valid: 87.61%, Test: 98.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 351, Loss: 0.1656, Valid: 69.25%, Test: 84.51%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 351, Loss: 0.1656, Valid: 73.59%, Test: 97.02%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 351, Loss: 0.1656, Valid: 96.94%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 352, Loss: 0.1650, Valid: 69.64%, Test: 89.25%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 352, Loss: 0.1650, Valid: 74.18%, Test: 97.42%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 352, Loss: 0.1650, Valid: 98.11%, Test: 98.49%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 353, Loss: 0.1651, Valid: 69.81%, Test: 82.46%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 353, Loss: 0.1651, Valid: 73.27%, Test: 95.23%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 353, Loss: 0.1651, Valid: 94.62%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 354, Loss: 0.1653, Valid: 70.80%, Test: 80.23%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 354, Loss: 0.1653, Valid: 73.87%, Test: 96.57%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 354, Loss: 0.1653, Valid: 98.36%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 355, Loss: 0.1654, Valid: 68.54%, Test: 76.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 355, Loss: 0.1654, Valid: 73.05%, Test: 94.60%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 355, Loss: 0.1654, Valid: 97.07%, Test: 98.43%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 356, Loss: 0.1659, Valid: 70.63%, Test: 85.81%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 356, Loss: 0.1659, Valid: 73.85%, Test: 95.55%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 356, Loss: 0.1659, Valid: 98.04%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 357, Loss: 0.1654, Valid: 71.11%, Test: 79.97%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 357, Loss: 0.1654, Valid: 73.31%, Test: 94.74%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 357, Loss: 0.1654, Valid: 96.99%, Test: 98.53%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 358, Loss: 0.1663, Valid: 71.43%, Test: 83.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 358, Loss: 0.1663, Valid: 75.35%, Test: 97.26%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 358, Loss: 0.1663, Valid: 98.46%, Test: 98.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 359, Loss: 0.1657, Valid: 69.33%, Test: 81.94%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 359, Loss: 0.1657, Valid: 73.14%, Test: 96.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 359, Loss: 0.1657, Valid: 97.66%, Test: 98.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 360, Loss: 0.1643, Valid: 70.01%, Test: 75.50%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 360, Loss: 0.1643, Valid: 73.05%, Test: 93.65%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 360, Loss: 0.1643, Valid: 95.37%, Test: 98.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 361, Loss: 0.1645, Valid: 70.30%, Test: 82.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 361, Loss: 0.1645, Valid: 73.58%, Test: 96.30%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 361, Loss: 0.1645, Valid: 98.17%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 362, Loss: 0.1653, Valid: 71.27%, Test: 66.30%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 362, Loss: 0.1653, Valid: 73.49%, Test: 96.86%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 362, Loss: 0.1653, Valid: 97.78%, Test: 98.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 363, Loss: 0.1647, Valid: 70.34%, Test: 84.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 363, Loss: 0.1647, Valid: 77.81%, Test: 97.12%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 363, Loss: 0.1647, Valid: 98.74%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 364, Loss: 0.1655, Valid: 70.41%, Test: 65.82%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 364, Loss: 0.1655, Valid: 73.15%, Test: 95.00%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 364, Loss: 0.1655, Valid: 95.17%, Test: 98.33%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 365, Loss: 0.1652, Valid: 71.07%, Test: 83.64%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 365, Loss: 0.1652, Valid: 73.69%, Test: 96.46%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 365, Loss: 0.1652, Valid: 97.36%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 366, Loss: 0.1657, Valid: 70.91%, Test: 88.55%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 366, Loss: 0.1657, Valid: 81.57%, Test: 96.53%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 366, Loss: 0.1657, Valid: 98.71%, Test: 98.64%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 367, Loss: 0.1656, Valid: 70.03%, Test: 85.94%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 367, Loss: 0.1656, Valid: 73.59%, Test: 94.85%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 367, Loss: 0.1656, Valid: 97.33%, Test: 98.35%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 368, Loss: 0.1647, Valid: 70.69%, Test: 76.58%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 368, Loss: 0.1647, Valid: 73.52%, Test: 94.87%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 368, Loss: 0.1647, Valid: 97.57%, Test: 98.44%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 369, Loss: 0.1664, Valid: 69.96%, Test: 85.37%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 369, Loss: 0.1664, Valid: 73.11%, Test: 96.28%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 369, Loss: 0.1664, Valid: 96.06%, Test: 98.45%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 370, Loss: 0.1651, Valid: 70.56%, Test: 76.32%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 370, Loss: 0.1651, Valid: 74.01%, Test: 96.49%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 370, Loss: 0.1651, Valid: 97.61%, Test: 98.54%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 371, Loss: 0.1647, Valid: 69.77%, Test: 78.45%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 371, Loss: 0.1647, Valid: 76.12%, Test: 95.87%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 371, Loss: 0.1647, Valid: 98.29%, Test: 98.43%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 372, Loss: 0.1647, Valid: 70.70%, Test: 70.08%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 372, Loss: 0.1647, Valid: 73.46%, Test: 96.28%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 372, Loss: 0.1647, Valid: 97.11%, Test: 98.63%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 373, Loss: 0.1643, Valid: 70.95%, Test: 84.97%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 373, Loss: 0.1643, Valid: 75.62%, Test: 95.98%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 373, Loss: 0.1643, Valid: 98.50%, Test: 98.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 374, Loss: 0.1661, Valid: 70.43%, Test: 79.57%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 374, Loss: 0.1661, Valid: 73.70%, Test: 96.51%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 374, Loss: 0.1661, Valid: 97.36%, Test: 98.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 375, Loss: 0.1648, Valid: 71.35%, Test: 73.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 375, Loss: 0.1648, Valid: 73.35%, Test: 95.32%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 375, Loss: 0.1648, Valid: 96.74%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 376, Loss: 0.1640, Valid: 70.63%, Test: 82.33%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 376, Loss: 0.1640, Valid: 76.01%, Test: 96.49%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 376, Loss: 0.1640, Valid: 97.96%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 377, Loss: 0.1655, Valid: 71.72%, Test: 79.21%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 377, Loss: 0.1655, Valid: 73.60%, Test: 96.48%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 377, Loss: 0.1655, Valid: 97.07%, Test: 98.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 378, Loss: 0.1650, Valid: 69.82%, Test: 81.24%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 378, Loss: 0.1650, Valid: 73.40%, Test: 95.64%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 378, Loss: 0.1650, Valid: 92.19%, Test: 98.73%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 379, Loss: 0.1641, Valid: 70.72%, Test: 75.08%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 379, Loss: 0.1641, Valid: 73.34%, Test: 96.73%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 379, Loss: 0.1641, Valid: 96.71%, Test: 98.71%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 380, Loss: 0.1639, Valid: 70.86%, Test: 83.04%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 380, Loss: 0.1639, Valid: 73.44%, Test: 97.29%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 380, Loss: 0.1639, Valid: 98.43%, Test: 98.79%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 381, Loss: 0.1638, Valid: 70.02%, Test: 58.67%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 381, Loss: 0.1638, Valid: 73.28%, Test: 93.39%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 381, Loss: 0.1638, Valid: 94.15%, Test: 98.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 382, Loss: 0.1639, Valid: 69.91%, Test: 75.08%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 382, Loss: 0.1639, Valid: 73.58%, Test: 96.04%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 382, Loss: 0.1639, Valid: 98.11%, Test: 98.58%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 383, Loss: 0.1647, Valid: 69.62%, Test: 79.65%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 383, Loss: 0.1647, Valid: 73.42%, Test: 94.67%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 383, Loss: 0.1647, Valid: 96.30%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 384, Loss: 0.1652, Valid: 71.70%, Test: 74.43%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 384, Loss: 0.1652, Valid: 73.49%, Test: 94.98%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 384, Loss: 0.1652, Valid: 95.34%, Test: 98.47%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 385, Loss: 0.1642, Valid: 71.81%, Test: 79.62%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 385, Loss: 0.1642, Valid: 73.68%, Test: 95.82%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 385, Loss: 0.1642, Valid: 96.94%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 386, Loss: 0.1647, Valid: 71.04%, Test: 85.65%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 386, Loss: 0.1647, Valid: 83.84%, Test: 95.91%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 386, Loss: 0.1647, Valid: 98.64%, Test: 98.48%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 387, Loss: 0.1643, Valid: 70.45%, Test: 86.38%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 387, Loss: 0.1643, Valid: 76.26%, Test: 96.18%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 387, Loss: 0.1643, Valid: 98.38%, Test: 98.52%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 388, Loss: 0.1641, Valid: 68.68%, Test: 70.80%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 388, Loss: 0.1641, Valid: 73.51%, Test: 96.02%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 388, Loss: 0.1641, Valid: 96.05%, Test: 98.39%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 389, Loss: 0.1649, Valid: 69.39%, Test: 83.58%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 389, Loss: 0.1649, Valid: 90.26%, Test: 97.04%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 389, Loss: 0.1649, Valid: 98.72%, Test: 98.56%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 390, Loss: 0.1651, Valid: 69.23%, Test: 65.91%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 390, Loss: 0.1651, Valid: 73.17%, Test: 92.41%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 390, Loss: 0.1651, Valid: 96.40%, Test: 98.32%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 391, Loss: 0.1650, Valid: 70.63%, Test: 72.93%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 391, Loss: 0.1650, Valid: 79.38%, Test: 96.13%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 391, Loss: 0.1650, Valid: 98.50%, Test: 98.72%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 392, Loss: 0.1639, Valid: 71.81%, Test: 81.42%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 392, Loss: 0.1639, Valid: 73.59%, Test: 96.91%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 392, Loss: 0.1639, Valid: 97.08%, Test: 98.61%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 393, Loss: 0.1643, Valid: 71.61%, Test: 83.88%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 393, Loss: 0.1643, Valid: 79.74%, Test: 96.47%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 393, Loss: 0.1643, Valid: 98.86%, Test: 98.70%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 394, Loss: 0.1626, Valid: 69.66%, Test: 72.82%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 394, Loss: 0.1626, Valid: 73.52%, Test: 95.08%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 394, Loss: 0.1626, Valid: 96.55%, Test: 98.65%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 395, Loss: 0.1639, Valid: 69.80%, Test: 87.23%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 395, Loss: 0.1639, Valid: 80.13%, Test: 97.14%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 395, Loss: 0.1639, Valid: 98.65%, Test: 98.77%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 396, Loss: 0.1629, Valid: 70.10%, Test: 84.93%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 396, Loss: 0.1629, Valid: 85.43%, Test: 97.18%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 396, Loss: 0.1629, Valid: 98.49%, Test: 98.51%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 397, Loss: 0.1643, Valid: 70.12%, Test: 81.91%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 397, Loss: 0.1643, Valid: 74.88%, Test: 96.98%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 397, Loss: 0.1643, Valid: 98.12%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 398, Loss: 0.1646, Valid: 70.65%, Test: 80.81%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 398, Loss: 0.1646, Valid: 84.17%, Test: 97.12%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 398, Loss: 0.1646, Valid: 98.48%, Test: 98.67%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 399, Loss: 0.1632, Valid: 69.85%, Test: 86.61%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 399, Loss: 0.1632, Valid: 74.36%, Test: 97.38%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 399, Loss: 0.1632, Valid: 98.43%, Test: 98.57%\n",
      "---\n",
      "Hits@20\n",
      "Run: 02, Epoch: 400, Loss: 0.1632, Valid: 70.59%, Test: 57.76%\n",
      "Hits@50\n",
      "Run: 02, Epoch: 400, Loss: 0.1632, Valid: 73.46%, Test: 93.25%\n",
      "Hits@100\n",
      "Run: 02, Epoch: 400, Loss: 0.1632, Valid: 92.83%, Test: 98.50%\n",
      "---\n",
      "Hits@20\n",
      "Run 02:\n",
      "Highest Valid: 71.81\n",
      "   Final Test: 79.62\n",
      "Hits@50\n",
      "Run 02:\n",
      "Highest Valid: 90.26\n",
      "   Final Test: 97.04\n",
      "Hits@100\n",
      "Run 02:\n",
      "Highest Valid: 98.86\n",
      "   Final Test: 98.70\n",
      "Hits@20\n",
      "All runs:\n",
      "Highest Valid: 72.4183 ± 0.8553\n",
      "   Final Test: 81.9904 ± 3.3530\n",
      "Hits@50\n",
      "All runs:\n",
      "Highest Valid: 92.2924 ± 2.8694\n",
      "   Final Test: 97.1389 ± 0.1459\n",
      "Hits@100\n",
      "All runs:\n",
      "Highest Valid: 98.9826 ± 0.1725\n",
      "   Final Test: 98.7682 ± 0.0948\n"
     ]
    }
   ],
   "source": [
    "for run in range(runs):\n",
    "    random.seed(run)\n",
    "    torch.manual_seed(run)\n",
    "    torch.nn.init.xavier_uniform_(emb.weight)\n",
    "    torch.nn.init.xavier_uniform_(emb_ea.weight)\n",
    "    model.reset_parameters()\n",
    "    predictor.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(model.parameters()) + list(emb.parameters()) +\n",
    "        list(emb_ea.parameters()) + list(predictor.parameters()), lr=lr)\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        loss = train(model, predictor, edge_attr, emb.weight, emb_ea.weight, edge_index, train_pos,\n",
    "                      optimizer, batch_size)\n",
    "\n",
    "        if epoch % eval_steps == 0:\n",
    "            results, pos_valid_pred, neg_valid_pred, pos_test_pred, neg_test_pred = test(model, predictor, edge_attr, emb.weight, emb_ea.weight, edge_index, valid_pos, valid_neg, test_pos, test_neg,\n",
    "                            evaluator, batch_size)\n",
    "            for key, result in results.items():\n",
    "                loggers[key].add_result(run, result)\n",
    "\n",
    "            if epoch % log_steps == 0:\n",
    "                for key, result in results.items():\n",
    "                    valid_hits, test_hits = result\n",
    "                    print(key)\n",
    "                    print(f'Run: {run + 1:02d}, '\n",
    "                          f'Epoch: {epoch:02d}, '\n",
    "                          f'Loss: {loss:.4f}, '\n",
    "                          f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                          f'Test: {100 * test_hits:.2f}%')\n",
    "                print('---')\n",
    "\n",
    "    for key in loggers.keys():\n",
    "        print(key)\n",
    "        loggers[key].print_statistics(run)\n",
    "\n",
    "for key in loggers.keys():\n",
    "    print(key)\n",
    "    loggers[key].print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-H19Eq3_H7R",
    "outputId": "c531191d-17d7-41ff-9d7b-fa3192b4db03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8543, 0.9810, 0.9821,  ..., 0.9696, 0.9829, 0.9816])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_valid_pred, neg_valid_pred, pos_test_pred, neg_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pk8x1gOS_ID7"
   },
   "outputs": [],
   "source": [
    "with open('pos_valid_pred.pickle', 'wb') as handle:\n",
    "    pickle.dump(pos_valid_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('neg_valid_pred.pickle', 'wb') as handle:\n",
    "    pickle.dump(neg_valid_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pos_test_pred.pickle', 'wb') as handle:\n",
    "    pickle.dump(pos_test_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('neg_test_pred.pickle', 'wb') as handle:\n",
    "    pickle.dump(neg_test_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTPgy6m_kOh8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4l8BXWzP_IGd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRTlnEdyj6eI"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9FShU_Sj6gb"
   },
   "outputs": [],
   "source": [
    "emb = node_features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce9RGzebj6i4"
   },
   "outputs": [],
   "source": [
    "data = T.ToSparseTensor()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvXJABpckDlc"
   },
   "outputs": [],
   "source": [
    "adj_t = data.adj_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgCpU57YkF2-",
    "outputId": "63097af0-7e21-414a-fca0-8f559da82736"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([   0,    0,    0,  ..., 3538, 3538, 3538], device='cuda:0'),\n",
       "             col=tensor([  29,   31,   39,  ..., 2976, 3034, 3356], device='cuda:0'),\n",
       "             size=(3539, 3539), nnz=1774468, density=14.17%)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qNTyP89kHov"
   },
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout, aggr=\"add\"):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, normalize=True, aggr=aggr))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "class DotProductLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DotProductLinkPredictor, self).__init__()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        out = (x_i*x_j).sum(-1)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvvE0_dnkKnb"
   },
   "outputs": [],
   "source": [
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = SAGE(2048, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = DotProductLinkPredictor().to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(emb, adj_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcSG0IwWkMLE",
    "outputId": "2ec92a85-fc53-41eb-8f3a-c58b5bd2309c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.7311, 0.7311, 0.7310, 0.7311, 0.7311, 0.7311, 0.7311, 0.7310,\n",
       "        0.7311], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly sample some training edges and pass them through our basic predictor\n",
    "idx = torch.randperm(train_pos.size(0))[:10]\n",
    "edges = train_pos[idx].t()\n",
    "predictor(h[edges[0]], h[edges[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTXY78Xxtosi",
    "outputId": "2936397a-1fbd-45f1-a113-2fc0bf4b7b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    0,    0,  ..., 3538, 3538, 3538], device='cuda:0'),\n",
       " tensor([  29,   31,   39,  ..., 2976, 3034, 3356], device='cuda:0'),\n",
       " None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_t.t().coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFMcy4XMkNSn"
   },
   "outputs": [],
   "source": [
    "def create_train_batch(all_pos_train_edges, perm, edge_index):\n",
    "    # First, we get our positive edges, reshaping them to the form (2, hidden_dimension)\n",
    "    pos_edges = all_pos_train_edges[perm].t().to(device)\n",
    "\n",
    "    # We then sample the negative edges using PyG functionality\n",
    "    neg_edges = negative_sampling(edge_index, num_nodes=3539,\n",
    "                                  num_neg_samples=perm.shape[0], method='dense').to(device)\n",
    "\n",
    "    # Our training batch is just the positive edges concatanted with the negative ones\n",
    "    train_edge = torch.cat([pos_edges, neg_edges], dim=1)\n",
    "\n",
    "    # Our labels are all 1 for the positive edges and 0 for the negative ones\n",
    "    pos_label = torch.ones(pos_edges.shape[1], )\n",
    "    neg_label = torch.zeros(neg_edges.shape[1], )\n",
    "    train_label = torch.cat([pos_label, neg_label], dim=0).to(device)\n",
    "\n",
    "    return train_edge, train_label\n",
    "\n",
    "def train(model, predictor, x, adj_t, train_edge, loss_fn, optimizer, batch_size, num_epochs, edge_model=False, spd=None):\n",
    "  # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
    "  row, col, edge_attr = adj_t.t().coo()\n",
    "  edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "  model.train()\n",
    "  predictor.train()\n",
    "\n",
    "  model.reset_parameters()\n",
    "  predictor.reset_parameters()\n",
    "\n",
    "  all_pos_train_edges = train_edge\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_total_loss = 0\n",
    "    for perm in DataLoader(range(all_pos_train_edges.shape[0]), batch_size,\n",
    "                           shuffle=True):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
    "\n",
    "      # Use the GNN to generate node embeddings\n",
    "      if edge_model:\n",
    "        h = model(x, edge_index, spd)\n",
    "      else:\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "      # Get predictions for our batch and compute the loss\n",
    "      preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
    "      loss = loss_fn(preds, train_label)\n",
    "\n",
    "      epoch_total_loss += loss.item()\n",
    "\n",
    "      # Update our parameters\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "    print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyxQPcNckR9E",
    "outputId": "463e9593-f875-44dc-a53e-91d89ec54fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ddi\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred, label):\n",
    "  pred_rounded = torch.round(pred)\n",
    "  accu = torch.eq(pred_rounded, label).sum() / label.shape[0]\n",
    "  accu = round(accu.item(), 4)\n",
    "  return accu\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge_pos, split_edge_neg, evaluator, batch_size, edge_model=False, spd=None):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    if edge_model:\n",
    "        # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index\n",
    "        row, col, edge_attr = adj_t.t().coo()\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        h = model(x, edge_index, spd)\n",
    "    else:\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "    pos_eval_edge = split_edge_pos.to(device)\n",
    "    neg_eval_edge = split_edge_neg.to(device)\n",
    "\n",
    "    pos_eval_preds = []\n",
    "    for perm in DataLoader(range(pos_eval_edge.shape[0]), batch_size):\n",
    "        edge = pos_eval_edge[perm].t()\n",
    "        pos_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_eval_pred = torch.cat(pos_eval_preds, dim=0)\n",
    "\n",
    "    neg_eval_preds = []\n",
    "    for perm in DataLoader(range(neg_eval_edge.size(0)), batch_size):\n",
    "        edge = neg_eval_edge[perm].t()\n",
    "        neg_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_eval_pred = torch.cat(neg_eval_preds, dim=0)\n",
    "\n",
    "    total_preds = torch.cat((pos_eval_pred, neg_eval_pred), dim=0)\n",
    "    labels = torch.cat((torch.ones_like(pos_eval_pred), torch.zeros_like(neg_eval_pred)), dim=0)\n",
    "    acc = accuracy(total_preds, labels)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30, 40, 50]:\n",
    "        evaluator.K = K\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_eval_pred,\n",
    "            'y_pred_neg': neg_eval_pred,\n",
    "        })[f'hits@{K}']\n",
    "        results[f'Hits@{K}'] = (valid_hits)\n",
    "    results['Accuracy'] = acc\n",
    "\n",
    "    return results, pos_eval_pred, neg_eval_pred\n",
    "eval = Evaluator(name='ogbl-ddi')\n",
    "# ogb Evaluators can be invoked to get their expected format\n",
    "print(eval.expected_input_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykHxv3LskV21",
    "outputId": "ae6bab74-eb26-4175-bb16-4a7ff8d25eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 9.783\n",
      "Epoch 1 has loss 9.195\n",
      "Epoch 2 has loss 8.5566\n",
      "Epoch 3 has loss 8.2481\n",
      "Epoch 4 has loss 8.2215\n",
      "Epoch 5 has loss 8.1786\n",
      "Epoch 6 has loss 8.1583\n",
      "Epoch 7 has loss 8.1546\n",
      "Epoch 8 has loss 8.1457\n",
      "Epoch 9 has loss 8.1805\n",
      "Epoch 10 has loss 8.1378\n",
      "Epoch 11 has loss 8.1436\n",
      "Epoch 12 has loss 8.2384\n",
      "Epoch 13 has loss 8.1381\n",
      "Epoch 14 has loss 8.1053\n",
      "Epoch 15 has loss 8.0789\n",
      "Epoch 16 has loss 8.0385\n",
      "Epoch 17 has loss 8.0132\n",
      "Epoch 18 has loss 7.9893\n",
      "Epoch 19 has loss 7.9629\n",
      "Epoch 20 has loss 7.9628\n",
      "Epoch 21 has loss 7.9348\n",
      "Epoch 22 has loss 7.9473\n",
      "Epoch 23 has loss 7.9157\n",
      "Epoch 24 has loss 7.9022\n",
      "Epoch 25 has loss 7.8883\n",
      "Epoch 26 has loss 7.9069\n",
      "Epoch 27 has loss 7.8904\n",
      "Epoch 28 has loss 7.8803\n",
      "Epoch 29 has loss 7.8885\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, emb, adj_t, train_pos, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 30)\n",
    "test(model, predictor, emb, adj_t, valid_pos, valid_neg, Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyrOBkiblDsm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEt2gjOMlnJP"
   },
   "source": [
    "#Model Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y22MvJL3lmzw"
   },
   "outputs": [],
   "source": [
    "class SkipConnSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SkipConnSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_dimension, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "        self.convs.append(SAGEConv(hidden_dimension, out_channels, normalize=True, aggr=\"add\"))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        prev_x = None\n",
    "        for i in range(len(self.convs) - 1):\n",
    "          prev_x = x\n",
    "          x = self.convs[i](x, adj_t)\n",
    "          # Skip Connection\n",
    "          if i > 0:\n",
    "            x = x + prev_x\n",
    "          x = F.relu(x)\n",
    "          x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k66oeZ4nlm1k"
   },
   "outputs": [],
   "source": [
    "class PostProcessSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, out_channels, num_conv_layers,\n",
    "                 num_linear_layers, dropout):\n",
    "        super(PostProcessSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "        for _ in range(num_conv_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_dimension, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "\n",
    "        for _ in range(num_linear_layers - 1):\n",
    "            self.lins.append(torch.nn.Linear(hidden_dimension, hidden_dimension))\n",
    "        self.lins.append(torch.nn.Linear(hidden_dimension, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "\n",
    "        # Post-process\n",
    "        for lin in self.lins[:-1]:\n",
    "          x = lin(x)\n",
    "          x = F.relu(x)\n",
    "        x = self.lins[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dllWFMvLlm3W"
   },
   "outputs": [],
   "source": [
    "class NeuralLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(NeuralLinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TS0wqFO0lDvW",
    "outputId": "96550d9f-838d-4563-ba84-d77310aecded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 9.3322\n",
      "Epoch 1 has loss 8.3561\n",
      "Epoch 2 has loss 7.9216\n",
      "Epoch 3 has loss 8.1477\n",
      "Epoch 4 has loss 7.1912\n",
      "Epoch 5 has loss 6.5159\n",
      "Epoch 6 has loss 6.1057\n",
      "Epoch 7 has loss 5.9734\n",
      "Epoch 8 has loss 5.9502\n",
      "Epoch 9 has loss 5.8657\n",
      "Epoch 10 has loss 5.807\n",
      "Epoch 11 has loss 5.7704\n",
      "Epoch 12 has loss 5.9188\n",
      "Epoch 13 has loss 5.862\n",
      "Epoch 14 has loss 5.7531\n",
      "Epoch 15 has loss 5.7001\n",
      "Epoch 16 has loss 5.6568\n",
      "Epoch 17 has loss 5.7993\n",
      "Epoch 18 has loss 5.7442\n",
      "Epoch 19 has loss 5.4495\n",
      "Epoch 20 has loss 5.3639\n",
      "Epoch 21 has loss 5.2336\n",
      "Epoch 22 has loss 5.1209\n",
      "Epoch 23 has loss 5.0228\n",
      "Epoch 24 has loss 4.8656\n",
      "Epoch 25 has loss 4.8159\n",
      "Epoch 26 has loss 4.6775\n",
      "Epoch 27 has loss 4.5975\n",
      "Epoch 28 has loss 4.5301\n",
      "Epoch 29 has loss 4.7629\n",
      "Epoch 30 has loss 4.5344\n",
      "Epoch 31 has loss 4.4697\n",
      "Epoch 32 has loss 4.4174\n",
      "Epoch 33 has loss 4.415\n",
      "Epoch 34 has loss 4.3874\n",
      "Epoch 35 has loss 4.4274\n",
      "Epoch 36 has loss 4.3698\n",
      "Epoch 37 has loss 4.4142\n",
      "Epoch 38 has loss 4.3327\n",
      "Epoch 39 has loss 4.4014\n",
      "Epoch 40 has loss 4.4491\n",
      "Epoch 41 has loss 4.3466\n",
      "Epoch 42 has loss 4.3585\n",
      "Epoch 43 has loss 4.2936\n",
      "Epoch 44 has loss 4.2113\n",
      "Epoch 45 has loss 4.2339\n",
      "Epoch 46 has loss 4.1685\n",
      "Epoch 47 has loss 4.1969\n",
      "Epoch 48 has loss 4.1528\n",
      "Epoch 49 has loss 4.1764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Hits@10': 0.13005210723831637,\n",
       "  'Hits@20': 0.17434775956874285,\n",
       "  'Hits@30': 0.2434910949719665,\n",
       "  'Hits@40': 0.2606351863351242,\n",
       "  'Hits@50': 0.27728430393189163,\n",
       "  'Accuracy': 0.8741},\n",
       " tensor([0.6843, 0.9283, 0.9694,  ..., 0.8228, 0.9717, 0.9760]),\n",
       " tensor([0.2969, 0.0221, 0.6009,  ..., 0.0447, 0.1054, 0.1150]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAGE(2048 , hidden_dimension, hidden_dimension, 5, 0.3).to(device)\n",
    "predictor = NeuralLinkPredictor(hidden_dimension, hidden_dimension, 1, 4, 0.3).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, emb, adj_t, train_pos, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 50)\n",
    "test(model, predictor, emb, adj_t, valid_pos, valid_neg, Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "T5NJhFjElz9M",
    "outputId": "340cf1fa-6fed-45eb-849d-eb6a3723926b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-86b74944045c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_undirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'convert' is not defined"
     ]
    }
   ],
   "source": [
    "G = convert.to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07Gq3opllz_w"
   },
   "outputs": [],
   "source": [
    "K = 200\n",
    "sampled_nodes = sorted(random.sample(G.nodes, K))\n",
    "\n",
    "spd = torch.ones(3539, K, dtype=torch.float64).to(device)\n",
    "for k in range(K):\n",
    "  distance_from_sample_k_to_all_nodes = nx.shortest_path_length(G, source=sampled_nodes[k])\n",
    "  for node in distance_from_sample_k_to_all_nodes:\n",
    "    spd[node][k] = distance_from_sample_k_to_all_nodes[node]\n",
    "spd = spd.float()\n",
    "spd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE3geLHvl7BA"
   },
   "outputs": [],
   "source": [
    "class SAGEConvWithEdgesConceptual(MessagePassing):\n",
    "    def __init__(self, in_channels,\n",
    "                 out_channels, normalize = False,\n",
    "                 root_weight = True,\n",
    "                 bias = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(SAGEConvWithEdges, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = torch.nn.Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_e = torch.nn.Linear(1, in_channels[0], bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = torch.nn.Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_e.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, spd, size = None):\n",
    "        if isinstance(x, Tensor):\n",
    "            x = (x, x)\n",
    "        out = self.propagate(edge_index, x=x, spd=spd)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "          out = F.normalize(out, p=2., dim=-1)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, spd_i, spd_j):\n",
    "        dist_mean = torch.mean(spd_i + spd_j, 1, True)\n",
    "        return F.relu(x_j + self.lin_e(dist_mean))\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhvHZKFjl7DB"
   },
   "outputs": [],
   "source": [
    "class SAGEConvWithEdges(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels,\n",
    "                 out_channels, normalize = False,\n",
    "                 root_weight = True,\n",
    "                 bias = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(SAGEConvWithEdges, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = torch.nn.Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_e = torch.nn.Linear(1, in_channels[0])\n",
    "        if self.root_weight:\n",
    "            self.lin_r = torch.nn.Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_e.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, spd, size = None):\n",
    "        if isinstance(x, Tensor):\n",
    "            x = (x, x)\n",
    "\n",
    "        spd = torch.sum(spd, dim=1, keepdim=True) / spd.shape[1]\n",
    "        spd = self.lin_e(spd)\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, spd=spd)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, spd_i, spd_j):\n",
    "        dist_mean = F.relu(spd_i + spd_j)\n",
    "        return x_j + dist_mean\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t0BXXqKmBlN"
   },
   "outputs": [],
   "source": [
    "class EdgeSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout, aggr=\"mean\"):\n",
    "        super(EdgeSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConvWithEdges(in_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConvWithEdges(hidden_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        self.convs.append(SAGEConvWithEdges(hidden_channels, out_channels, normalize=True, aggr=aggr))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, spd):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index, spd)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index, spd)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TKW6eMZmBnW"
   },
   "outputs": [],
   "source": [
    "hidden_dimension = 1024\n",
    "model = EdgeSAGE(2048, hidden_dimension, hidden_dimension, 5, 0.3, aggr=\"add\").to(device)\n",
    "predictor = NeuralLinkPredictor(hidden_dimension, hidden_dimension, 1, 4, 0.3).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.003)\n",
    "train(model, predictor, emb, adj_t, train_pos, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 100, edge_model=True, spd=spd)\n",
    "test(model, predictor, emb, adj_t, valid_pos, valid_neg, Evaluator(name='ogbl-ddi'), 64*1024, edge_model=True, spd=spd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1Cxq8O6mBql"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Q-hpDC4mBs9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ez-t_HACmBva"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VJvpS__kaA8"
   },
   "outputs": [],
   "source": [
    "KEKW, pos, neg = test(model, predictor, emb, adj_t, valid_pos, valid_neg, Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
